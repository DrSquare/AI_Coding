{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrSquare/AI_Coding/blob/main/hw_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzTQZ_itJ8hK"
      },
      "source": [
        "# Homework and bakeoff: Multi-domain sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NYl5ZGwiBg_E"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Christopher Potts\"\n",
        "__version__ = \"CS224u, Stanford, Spring 2023\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKG_i0EBBg_G"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/main/hw_sentiment.ipynb)\n",
        "\n",
        "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKl8VxLEBg_G"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCsLrlg2Bg_G"
      },
      "source": [
        "This homework and associated bakeoff are devoted to supervised sentiment analysis in a ternary label setting (positive, negative, neutral). Your ultimate goal is to develop systems that can make accurate predictions in multiple domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-iOkJIyBg_H"
      },
      "source": [
        "The homework questions ask you to implement some baseline systems using DynaSent Round 1, DynaSent Round 2, and the Stanford Sentiment Treebank. The bakeoff challenge is to define a system that does well on the DynaSent test sets, the SST-3 test set, and a set of mystery examples that don't correspond to the DynaSent or SST-3 domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGMV-AAtBg_H"
      },
      "source": [
        "__Important methodological note:__ The DynaSent and SST-3 test sets are already publicly distributed, so we are counting on people not to cheat by developing their models on these test sets. You must do all your development without using these test sets at all, and then evaluate exactly once on the test set and turn in the results, with no further system tuning or additional runs. _Much of the scientific integrity of our field depends on people adhering to this honor code._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkjFQFb2Bg_H"
      },
      "source": [
        "This notebook briefly introduces our three development datasets, states the homework questions, and then provides guidance on the original system and associated bakeoff entry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsLcqWtBJ8hM"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nFUcNIhJ8hM",
        "outputId": "168814f0-5ca8-4007-ed2d-5aebefbc1197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs224u'...\n",
            "remote: Enumerating objects: 2409, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 2409 (delta 150), reused 127 (delta 119), pack-reused 2177 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2409/2409), 41.76 MiB | 44.40 MiB/s, done.\n",
            "Resolving deltas: 100% (1467/1467), done.\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.7 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: pytest>=7.1 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 6)) (8.3.5)\n",
            "Collecting jupyter>=1.0.0 (from -r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: transformers>=4.37 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 16)) (4.48.3)\n",
            "Collecting datasets>=2.14.6 (from -r cs224u/requirements.txt (line 17))\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: spacy>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 18)) (3.7.5)\n",
            "Collecting colbert-ai>=0.2.20 (from -r cs224u/requirements.txt (line 19))\n",
            "  Downloading colbert_ai-0.2.21-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dspy-ai==2.4.13 (from -r cs224u/requirements.txt (line 21))\n",
            "  Downloading dspy_ai-2.4.13-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting python-dotenv (from -r cs224u/requirements.txt (line 22))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting wget (from -r cs224u/requirements.txt (line 23))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai==1.61.1 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 24)) (1.61.1)\n",
            "Collecting backoff (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (1.4.2)\n",
            "Collecting optuna (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.10.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.32.3)\n",
            "Collecting structlog (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading structlog-25.2.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (4.67.1)\n",
            "Collecting ujson (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->-r cs224u/requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.7->-r cs224u/requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->-r cs224u/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->-r cs224u/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (3.11.13)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.15.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.5.0)\n",
            "Collecting bitarray (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading bitarray-3.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.0)\n",
            "Collecting git-python (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Collecting ninja (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.18.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (7.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.2)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.44)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.18.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.2.0)\n",
            "Collecting alembic>=1.5.0 (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.0.39)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.3.6)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.17.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (3.1.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading dspy_ai-2.4.13-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colbert_ai-0.2.21-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bitarray-3.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.5/301.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-25.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=abd913336300dc0f9073108b3fd152c7e05309e55639a00cb30b5e89d4b3d360\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, bitarray, xxhash, uri-template, ujson, types-python-dateutil, structlog, rfc3986-validator, rfc3339-validator, python-json-logger, python-dotenv, overrides, ninja, Mako, json5, jedi, fqdn, dill, colorlog, backoff, async-lru, multiprocess, jupyter-server-terminals, jupyter-client, arrow, alembic, optuna, isoduration, git-python, datasets, jupyter-events, dspy-ai, colbert-ai, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 arrow-1.3.0 async-lru-2.0.5 backoff-2.2.1 bitarray-3.1.1 colbert-ai-0.2.21 colorlog-6.9.0 datasets-3.4.0 dill-0.3.8 dspy-ai-2.4.13 fqdn-1.5.1 git-python-1.0.3 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 multiprocess-0.70.16 ninja-1.11.1.3 optuna-4.2.1 overrides-7.7.0 python-dotenv-1.0.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 structlog-25.2.0 types-python-dateutil-2.9.0.20241206 ujson-5.10.0 uri-template-1.3.0 wget-3.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Sort of randomly chosen import to see whether the requirements\n",
        "    # are met:\n",
        "    import datasets\n",
        "except ModuleNotFoundError:\n",
        "    !git clone https://github.com/cgpotts/cs224u/\n",
        "    !pip install -r cs224u/requirements.txt\n",
        "    import sys\n",
        "    sys.path.append(\"cs224u\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pyAzJmyYSNMP"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdJba1bGJ8hN"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGAwU8KmJ8hN"
      },
      "source": [
        "### DynaSent round 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTV-C1DkBg_I"
      },
      "source": [
        "The DynaSent dataset of [Potts, Wu, et al. 2021](https://aclanthology.org/2021.acl-long.186/) is a ternary sentiment benchmark consisting of two rounds (so far). The dataset is available on [Hugging Face](https://huggingface.co/datasets/dynabench/dynasent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVyl0w3QBg_I"
      },
      "source": [
        "For Round 1, the authors collected sentences from the [Yelp Academic Dataset](https://www.yelp.com/dataset) that fooled a top-performing sentiment model but were intuitive for humans. The model was used only to heuristically find the examples. Crowdworkers multiply-labeled all of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RpFhHv5Bg_I"
      },
      "source": [
        "The round contains a lot of metadata that could be useful for developing sentiment models. We will focus on just the sentences and labels, but you are free to make use of this additional metadata in developing uour system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9UcNgx_SZDG",
        "outputId": "e57d981e-5316-458d-c2d3-b65ed3ff05b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "dynasent_r1 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r1.all', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7iN05xzSkKo",
        "outputId": "cf92b175-db5b-4cd2-a721-898c587d2367"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 80488\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
              "        num_rows: 3600\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "dynasent_r1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_iWixX6J8hO"
      },
      "source": [
        "Splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RVjcdb_4SrS2"
      },
      "outputs": [],
      "source": [
        "def print_label_dist(dataset, labelname='gold_label', splitnames=('train', 'validation')):\n",
        "    for splitname in splitnames:\n",
        "        print(splitname)\n",
        "        dist = sorted(Counter(dataset[splitname][labelname]).items())\n",
        "        for k, v in dist:\n",
        "            print(f\"\\t{k:>14s}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3RQdIBRJ8hP",
        "outputId": "48506dbd-9f8b-408a-e6ba-567adf03e457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 14021\n",
            "\t       neutral: 45076\n",
            "\t      positive: 21391\n",
            "validation\n",
            "\t      negative: 1200\n",
            "\t       neutral: 1200\n",
            "\t      positive: 1200\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4WFt0C6J8hP"
      },
      "source": [
        "### DynaSent round 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNIaYBaABg_J"
      },
      "source": [
        "DynaSent Round 2 was created using different methods than Round 1. For Round 2, crowdworkers edited sentences from the Yelp Academic Dataset seeking to achieve a particular sentiment goal (e.g., expressing a positive sentiment) while fooling a top-performing model. This work was done on the [Dynabench](https://dynabench.org) platform. The hope is that this directly adversarial goal will lead to examples that are very hard for present-day models but intuitive for humans. All the examples were multiply-labeled by separate annotators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz3F_lviJ8hP",
        "outputId": "4f8fbb79-2104-4707-dd42-f2cbd980b52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "dynasent_r2 = load_dataset(\"dynabench/dynasent\", 'dynabench.dynasent.r2.all', trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up68q68dJ8hP",
        "outputId": "74bd5baf-4c2c-4d87-cd05-5bff457e59ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 4579\n",
            "\t       neutral: 2448\n",
            "\t      positive: 6038\n",
            "validation\n",
            "\t      negative: 240\n",
            "\t       neutral: 240\n",
            "\t      positive: 240\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(dynasent_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeONNIJQJ8hP"
      },
      "source": [
        "### Stanford Sentiment Treebank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rp-6oymBg_J"
      },
      "source": [
        "The [Stanford Sentiment Treebank (SST)](http://nlp.stanford.edu/sentiment/) of [Socher et al. 2013](https://aclanthology.org/D13-1170/) is a widely-used resource for evaluating supervised models. It consists of sentences from Rotten Tomatoes Movie Reviews (see [Pang and Lee's project page](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.home.html)). We will use the ternary version of the task (SST-3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UnS3gl7Bg_J"
      },
      "source": [
        "SST examples are special in that they are labeled at the phrase-level as well as the sentence level, which provides very extensive and detailed supervision for sentiment. We will use only the sentence-level labels for the homework, but you are free to use the phrase-level labels as well in designing your original system. (To do this, you will need to get the dataset from the above project page, since the Hugging Face SST-3 we are using does not include these labels.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJROF2MaJ8hP",
        "outputId": "0097599f-9a9f-4272-effc-a8aeefcd1efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "sst = load_dataset(\"SetFit/sst5\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw0I60nOJ8hQ",
        "outputId": "e64a2e80-0c76-471f-c390-c2c75bf46368"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 8544\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 1101\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'label_text'],\n",
              "        num_rows: 2210\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "sst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqDgWUoiBg_K"
      },
      "source": [
        "Out of the box, this is a five-way task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxmbH6qkJ8hQ",
        "outputId": "7302b64c-88f1-419b-f53e-076db81646c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 2218\n",
            "\t       neutral: 1624\n",
            "\t      positive: 2322\n",
            "\t very negative: 1092\n",
            "\t very positive: 1288\n",
            "validation\n",
            "\t      negative: 289\n",
            "\t       neutral: 229\n",
            "\t      positive: 279\n",
            "\t very negative: 139\n",
            "\t very positive: 165\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst, labelname='label_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3uqBd_Bg_K"
      },
      "source": [
        "The above labels are not aligned with our ternary task, and the dataset distribution uses slightly different keys from those of DynaSent. The following code converts the dataset to SST-3 and also aligns the dataset keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WDgWI8IzJ8hQ"
      },
      "outputs": [],
      "source": [
        "def convert_sst_label(s):\n",
        "    return s.split(\" \")[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UDT2FS0RJ8hQ"
      },
      "outputs": [],
      "source": [
        "for splitname in ('train', 'validation', 'test'):\n",
        "    dist = [convert_sst_label(s) for s in sst[splitname]['label_text']]\n",
        "    sst[splitname] = sst[splitname].add_column('gold_label', dist)\n",
        "    sst[splitname] = sst[splitname].add_column('sentence', sst[splitname]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dl9asPJ8hQ",
        "outputId": "f5284257-5f5b-4edb-f670-54b52d41358b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "\t      negative: 3310\n",
            "\t       neutral: 1624\n",
            "\t      positive: 3610\n",
            "validation\n",
            "\t      negative: 428\n",
            "\t       neutral: 229\n",
            "\t      positive: 444\n"
          ]
        }
      ],
      "source": [
        "print_label_dist(sst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRIt90tpBg_L"
      },
      "source": [
        "## Question 1: Linear classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHPgdpfuJ8hQ"
      },
      "source": [
        "Our first set of experiments will use simple linear classifiers with sparse representations derived from counting unigrams. These experiments will introduce some useful techniques and provide a baseline for original systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsHLZz7UBg_L"
      },
      "source": [
        "### Background: Feature functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXEkx2HRBg_Q"
      },
      "source": [
        "The following is a flexible format for writing feature functions in the context of scikit-learn modeling. The function maps a string to a count dictionary, using the simple procedure of splitting on whitespace and counting the resulting elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IHou4AJFBg_Q"
      },
      "outputs": [],
      "source": [
        "def unigrams_phi(s):\n",
        "    \"\"\"The basis for a unigrams feature function.\n",
        "\n",
        "    Downcases all tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "        The example to represent\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens (str) to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    return Counter(s.lower().split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdC0d6fBg_Q"
      },
      "source": [
        "Quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8C9X9QSBg_Q",
        "outputId": "d2a357bb-02a6-414f-91fc-143e1eaf70cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({\"here's\": 1,\n",
              "         'an': 2,\n",
              "         'example': 1,\n",
              "         'with': 1,\n",
              "         'emoticon': 1,\n",
              "         ':)!': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "unigrams_phi(\"Here's an example with an emoticon :)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ3UPu8IBg_R"
      },
      "source": [
        "### Background: Feature space vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp77-oroBg_R"
      },
      "source": [
        "Functions like `unigrams_phi`  are just the __basis__ for feature representations. In truth, our models typically don't represent examples as dictionaries, but rather as vectors embedded in a matrix. In general, to manage the translation from dictionaries to vectors, we use [sklearn.feature_extraction.DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) instances. Here's a brief overview of how these work:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkORf3ufBg_R"
      },
      "source": [
        "To start, suppose that we had just two examples to represent, and our feature function mapped them to the following list of dictionaries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RJytxHjeBg_R"
      },
      "outputs": [],
      "source": [
        "train_feats = [\n",
        "    {'a': 1, 'b': 1},\n",
        "    {'b': 1, 'c': 2}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR9CSo4jBg_R"
      },
      "source": [
        "Now we create a `DictVectorizer`. So that we can more easily inspect the resulting matrix, I've set `sparse=False`, so that the return value is a dense matrix. For real problems, you'll probably want to use `sparse=True`, as it will be vastly more efficient for the very sparse feature matrices that you are likely to be creating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "srnpUVSPBg_R"
      },
      "outputs": [],
      "source": [
        "vec = DictVectorizer(sparse=False)  # Use `sparse=True` for real problems!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52AiTRAfBg_R"
      },
      "source": [
        "The `fit_transform` method maps our list of dictionaries to a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "lJXdB1VsBg_R"
      },
      "outputs": [],
      "source": [
        "X_train = vec.fit_transform(train_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtLb-Z6gBg_S"
      },
      "source": [
        "Here I'll create a `pd.Datafame` just to help us inspect `X_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aN2ronbYBg_S",
        "outputId": "beaeea05-2b05-4623-98b9-beaea8c68b71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  1.0  1.0  0.0\n",
              "1  0.0  1.0  2.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6201c9c4-2dbc-4941-ace1-1a12a618dda5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6201c9c4-2dbc-4941-ace1-1a12a618dda5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6201c9c4-2dbc-4941-ace1-1a12a618dda5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6201c9c4-2dbc-4941-ace1-1a12a618dda5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4787261c-a57c-46b2-b067-c228583c828e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4787261c-a57c-46b2-b067-c228583c828e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4787261c-a57c-46b2-b067-c228583c828e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "pd.DataFrame(X_train, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ84-SwOBg_S"
      },
      "source": [
        "Now we can see that, intuitively, the feature called \"a\" is embedded in the first column, \"b\" in the second column, and \"c\" in the third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u151s16SBg_S"
      },
      "source": [
        "Now suppose we have some new test examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_JKt4fxOBg_S"
      },
      "outputs": [],
      "source": [
        "test_feats = [\n",
        "    {'a': 2, 'c': 1},\n",
        "    {'a': 4, 'b': 2, 'd': 1}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7kh3WKOBg_S"
      },
      "source": [
        "If we have trained a model on `X_train`, then it will not have any way to deal with this new feature \"d\". This shows that we need to embed `test_feats` in the same space as `X_train`. To do this, one just calls `transform` on the existing vectorizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qBAAyDWJBg_S"
      },
      "outputs": [],
      "source": [
        "X_test = vec.transform(test_feats)  # Not `fit_transform`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VZu_R_p2Bg_S",
        "outputId": "dfa8dce9-9edb-4849-f817-85bf6194fe88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     a    b    c\n",
              "0  2.0  0.0  1.0\n",
              "1  4.0  2.0  0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33548165-fde5-446a-8d67-4219165650e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33548165-fde5-446a-8d67-4219165650e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33548165-fde5-446a-8d67-4219165650e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33548165-fde5-446a-8d67-4219165650e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc297f60-8212-4be4-be51-cd727248d47b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc297f60-8212-4be4-be51-cd727248d47b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc297f60-8212-4be4-be51-cd727248d47b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 2.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4142135623730951,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "pd.DataFrame(X_test, columns=vec.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hxUpVRqBg_S"
      },
      "source": [
        "The most common mistake with `DictVectorizer` is calling `fit_transform` on test examples. This will wipe out the existing representation scheme, replacing it with one that matches the test examples. That will happen silently, but then you'll find that the new representations are incompatible with the model you fit. This is likely to manifest itself as a `ValueError` relating to feature counts. Here's an example that might help you spot this if and when it arises in your own work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7SNWQFiBg_T",
        "outputId": "0bc61c2d-e26f-4f08-f1c7-f3d14cfe7434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: X has 4 features, but LogisticRegression is expecting 3 features as input.\n"
          ]
        }
      ],
      "source": [
        "toy_mod = LogisticRegression()\n",
        "\n",
        "vec = DictVectorizer(sparse=False)\n",
        "\n",
        "X_train = vec.fit_transform(train_feats)\n",
        "\n",
        "toy_mod.fit(X_train, [0, 1])\n",
        "\n",
        "# Here's the error! Don't use `fit_transform` again!\n",
        "# Use `transform`!\n",
        "X_test = vec.fit_transform(test_feats)\n",
        "\n",
        "try:\n",
        "    toy_mod.predict(X_test)\n",
        "except ValueError as err:\n",
        "    print(\"ValueError: {}\".format(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9mAu4rxBg_T"
      },
      "source": [
        "### Background: scikit-learn models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ICav_SBg_T"
      },
      "source": [
        "scikit-learn is an amazing package with, among many other things, an incredible array of classifier model implementations. We're going to use a simple softmax classifier for this homework question, but you will find that you can swap in essentially any scikit-learn classifier and see how it does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnXrql6cBg_T"
      },
      "source": [
        "The core rhythm for scikit-learn models:\n",
        "\n",
        "1. Instantiate the model with any hyperparamters.\n",
        "2. `fit`\n",
        "3. `predict`\n",
        "\n",
        "Here's a quick example that also shows off scikit-learn's functionality for creating synthetic datasets and random train/test splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "puxqRxuGBg_T"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_toy, y_toy = make_classification(\n",
        "    n_samples=200, n_classes=3,\n",
        "    n_informative=15, n_features=20,\n",
        "    weights=[0.2, 0.2, 0.6],\n",
        "    random_state=1)\n",
        "\n",
        "X_toy_train, X_toy_test, y_toy_train, y_toy_test = train_test_split(\n",
        "    X_toy, y_toy, test_size=0.20, stratify=y_toy, random_state=1)\n",
        "\n",
        "toymod = LogisticRegression(penalty='l2', C=1, fit_intercept=True)\n",
        "\n",
        "toymod.fit(X_toy_train, y_toy_train)\n",
        "\n",
        "toypreds = toymod.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2SrgcCqBg_T"
      },
      "source": [
        "### Background: Classifier assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhr96l8mBg_T"
      },
      "source": [
        "When assessing a classifier, the best first step is usually to get a classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juZWuSKeBg_T",
        "outputId": "32b9ec52-d193-402c-e388-ec15d242a1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.444     0.500     0.471         8\n",
            "           1      0.444     0.500     0.471         8\n",
            "           2      0.909     0.833     0.870        24\n",
            "\n",
            "    accuracy                          0.700        40\n",
            "   macro avg      0.599     0.611     0.604        40\n",
            "weighted avg      0.723     0.700     0.710        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_toy_test, toypreds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-9aEmPOBg_T"
      },
      "source": [
        "In this course, we will generally focus in the __macro-average F1 score__ (macro avg above). This is simply the mean of the per-class F1 scores, without any attention paid to the overall size of the class. This is our default because, in NLP, we tend to care about small classes as much as (often more than) large classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tWfpEcKBg_U"
      },
      "source": [
        "The scikit-learn implementation of `macro_f1` can be finicky, so our course code provides a convenient wrapper:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvCZABTrBg_U",
        "outputId": "3fa47556-ff4a-49bc-87e1-b9eb8837e380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6035805626598466"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "import utils\n",
        "\n",
        "utils.safe_macro_f1(y_toy_test, toypreds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3jx3QypBg_U"
      },
      "source": [
        "Note: scikit-learn models have a `score` method. For classifiers, this is set to use `accuracy` by default:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abjCqC6RBg_U",
        "outputId": "6976ae82-3b84-4d1e-f247-ccafd6faafc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "toymod.score(X_toy_test, y_toy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Kf7JgUBg_U"
      },
      "source": [
        "Accuracy generally isn't well-aligned with our goals, so we discourage use of this method (and of accuracy scores in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpiawiz-Bg_U"
      },
      "source": [
        "scikit-learn also makes it very easy to perform automatic hyperparameter tuning. A quick example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-NeI4U5wBg_U"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'C': (0.1, 0.2, 0.3), 'fit_intercept': [True, False]}\n",
        "\n",
        "toymod_tuned = LogisticRegression()\n",
        "\n",
        "clf = GridSearchCV(toymod_tuned, params, scoring='f1_macro')\n",
        "\n",
        "_ = clf.fit(X_toy, y_toy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy4JcJhoBg_U"
      },
      "source": [
        "Here's the best model found by this search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "W2X8sqKRBg_U",
        "outputId": "34a4caa2-0707-40c9-d7c9-c2098ba65ec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.3, fit_intercept=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.3, fit_intercept=False)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "clf.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ixJb4McBg_V"
      },
      "source": [
        "Because we set `scoring='f1_macro'`, the above model was selected using our favored classifier scoring metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_jjxDKUBg_V",
        "outputId": "4f4429d4-e588-4854-e875-061ae7801ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6943888670150135"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r94T1wVcBg_W"
      },
      "source": [
        "With this best model in hand, we can perform our usual assessment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6dlNS7EoBg_W"
      },
      "outputs": [],
      "source": [
        "bestpreds = clf.best_estimator_.predict(X_toy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjdUltwLBg_W",
        "outputId": "145bbdf4-8bda-42b5-e689-c43fe161bda4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.750     0.600     0.667        10\n",
            "           1      0.750     0.750     0.750         8\n",
            "           2      0.833     0.909     0.870        22\n",
            "\n",
            "    accuracy                          0.800        40\n",
            "   macro avg      0.778     0.753     0.762        40\n",
            "weighted avg      0.796     0.800     0.795        40\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(bestpreds, y_toy_test, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QL_dVn_Bg_W"
      },
      "source": [
        "### Task 1: Feature functions [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO719nHBBg_W"
      },
      "source": [
        "The tokenization scheme used by `unigrams_phi` is very basic and leads to unintuitive tokens with punctuation attached to them. Your task here is to complete `tweetgrams_phi`, which should lead to more intuitive results. The task is really just to use the NLTK [TweetTokenizer](https://www.nltk.org/api/nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer) in place of the simple whitespace tokenization of `unigrams_phi` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1MtqNUtzBg_W"
      },
      "outputs": [],
      "source": [
        "# Your `tweetgrams_phi` should tokenize data according to this tokenizer from NLTK:\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "def tweetgrams_phi(s, **kwargs):\n",
        "    \"\"\"The basis for a feature function using `TweetTokenizer`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    s : str\n",
        "    kwargs : dict\n",
        "        Passed to `TweetTokenizer`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Counter\n",
        "        A map from tokens to their counts in `text`\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "    tokenizer = TweetTokenizer(**kwargs)\n",
        "    return Counter(tokenizer.tokenize(s))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8aTUXgtBg_X"
      },
      "source": [
        "Here's a test you can use to check that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "lTxviR3LBg_X"
      },
      "outputs": [],
      "source": [
        "def test_tweetgrams_phi(func):\n",
        "    examples = [\n",
        "        (\n",
        "            \"Here's an example with an emoticon :)\",\n",
        "            Counter({'an': 2, \"Here's\": 1, 'example': 1, 'with': 1, 'emoticon': 1, ':)': 1})\n",
        "        ),\n",
        "        (\n",
        "            \"The URL is https://pytorch.org!\",\n",
        "            Counter({'The': 1, 'URL': 1, 'is': 1, 'https://pytorch.org': 1, '!': 1})\n",
        "        )\n",
        "    ]\n",
        "    errcount = 0\n",
        "    for ex, expected in examples:\n",
        "        result = func(ex, preserve_case=True)\n",
        "        if result != expected:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{func.__name__}`: For input {ex}, \"\n",
        "                  f\"expected {expected} but got {result}\")\n",
        "    caps_ex = \"CAPS\"\n",
        "    caps_result = func(caps_ex, preserve_case=False)\n",
        "    caps_expected = Counter({\"caps\": 1})\n",
        "    if caps_result != caps_expected:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: For input {caps_ex}, \"\n",
        "              f\"expected {caps_expected} but got {caps_result}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"All tests passed for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLTAJpyBg_X",
        "outputId": "8b24d54e-a124-4799-eaaf-f84b0d251f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed for `tweetgrams_phi`\n"
          ]
        }
      ],
      "source": [
        "test_tweetgrams_phi(tweetgrams_phi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uIlGqZGJ8hR"
      },
      "source": [
        "### Task 2: Model training [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iMYndsIBg_X"
      },
      "source": [
        "Your task is to complete `train_linear_model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "rtEaAkHtStQg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "yfhADdcyJ8hR"
      },
      "outputs": [],
      "source": [
        "def train_linear_model(model, featfunc, train_dataset):\n",
        "    \"\"\"Train an sklearn classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : sklearn classifier model\n",
        "    featfunc : func\n",
        "        Maps strings to Counter instances\n",
        "    train_dataset: dict\n",
        "        Must have a key \"sentence\" containing strings that `featfunc`\n",
        "        will process, and a key \"gold_label\" giving labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        * A trained version of `model`\n",
        "        * A fitted `vectorizer` for the train set\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    # Step 1: Featurize all the examples in `train_dataset['sentence']`\n",
        "    ##### YOUR CODE HERE\n",
        "    train_feats = [featfunc(s) for s in train_dataset['sentence']]\n",
        "\n",
        "\n",
        "    # Step 2: Instantiate and use a `DictVectorizer`:\n",
        "    ##### YOUR CODE HERE\n",
        "    vec = DictVectorizer(sparse=True)\n",
        "    X_train = vec.fit_transform(train_feats)\n",
        "    y_train = train_dataset['gold_label']\n",
        "\n",
        "\n",
        "    # Step 3: Train the model on the feature matrix and\n",
        "    # train_dataset['gold_label']:\n",
        "    ##### YOUR CODE HERE\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Step 4: Return (model, vectorizer):\n",
        "    ##### YOUR CODE HERE\n",
        "    return (model, vec)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy2ok0-IBg_Y"
      },
      "source": [
        "You can use the following test to help ensure that your implementation is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "iBS6sQxWBg_Y"
      },
      "outputs": [],
      "source": [
        "def test_train_linear_model(func):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    result = func(model, featfunc, train_dataset)\n",
        "    if not isinstance(result, tuple) or len(result) != 2:\n",
        "        print(f\"Error for `{func.__name__}`: Incorrect return type\")\n",
        "        return\n",
        "    model, vectorizer = result\n",
        "    if not hasattr(vectorizer, 'vocabulary_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Second return value is not a trained vectorizer\")\n",
        "        return\n",
        "    if not hasattr(model, 'classes_'):\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"First return value is not a trained classifier\")\n",
        "        return\n",
        "    print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxHIjVDSBg_Y",
        "outputId": "4084b041-795f-41d3-90b9-92844f3e1211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `train_linear_model`\n"
          ]
        }
      ],
      "source": [
        "_ = test_train_linear_model(train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0aDjkXnBg_Y"
      },
      "source": [
        "You can now very easily train models on our datasets. Quick example (this shouldn't take more than a couple of minutes to run even on a CPU):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "OQoCRRPHJ8hR"
      },
      "outputs": [],
      "source": [
        "lr_unigrams, vec_unigrams = train_linear_model(\n",
        "    LogisticRegression(max_iter=1000),\n",
        "    unigrams_phi, dynasent_r1['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwbA2WCRBg_Z"
      },
      "source": [
        "### Task 3: Model assessment [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx_FQqRhBg_Z"
      },
      "source": [
        "Having now trained a model, we'd like to perform assessments on new data. Your task is to complete the wrapper function `assess_linear_model` to do this. The primary things you need to put into practice are (1) how to use a trained vectorizer on new data and (2) how to make predictions with your trained model. (Both of these steps are reviewed earlier in this notebook.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "GKa7uOwYJ8hR"
      },
      "outputs": [],
      "source": [
        "def assess_linear_model(model, featfunc, vectorizer, assess_dataset):\n",
        "    \"\"\"Assess a trained sklearn model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: trained sklearn model\n",
        "    featfunc : func\n",
        "        Maps strings to count dicts\n",
        "    vectorizer : fitted DictVectorizer\n",
        "    assess_dataset: dict\n",
        "        Must have a key \"sentence\" containing strings that `featfunc`\n",
        "        will process, and a key \"gold_label\" giving labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A classification report (multiline string)\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    # Step 1: Featurize the assessment data:\n",
        "    ##### YOUR CODE HERE\n",
        "    test_feats = [featfunc(s) for s in assess_dataset['sentence']]\n",
        "\n",
        "\n",
        "    # Step 2: Vectorize the assessment data features:\n",
        "    ##### YOUR CODE HERE\n",
        "    vec = vectorizer\n",
        "    X_test = vec.transform(test_feats)\n",
        "    y_test = assess_dataset['gold_label']\n",
        "\n",
        "\n",
        "    # Step 3: Make predictions:\n",
        "    ##### YOUR CODE HERE\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "    # Step 4: Return a classification report (str):\n",
        "    ##### YOUR CODE HERE\n",
        "    return classification_report(y_test, y_pred)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shk9E2ggBg_Z"
      },
      "source": [
        "Here's a quick test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "40pucaj6Bg_a"
      },
      "outputs": [],
      "source": [
        "def test_assess_linear_model(assessfunc, trainfunc):\n",
        "    train_dataset = {\n",
        "        'sentence': ['A A', 'A B', 'B B', 'B A', 'A', 'B'],\n",
        "        'gold_label': [0, 1, 0, 1, 0, 1]}\n",
        "    assess_dataset = {\n",
        "        'sentence': ['A C', 'B A'],\n",
        "        'gold_label': [0, 1]}\n",
        "    def featfunc(s):\n",
        "        return Counter(s.split())\n",
        "    model = LogisticRegression()\n",
        "    model, vectorizer = trainfunc(model, featfunc, train_dataset)\n",
        "    result = assessfunc(model, featfunc, vectorizer, assess_dataset)\n",
        "    errcount = 0\n",
        "    if len(vectorizer.vocabulary_) != 2:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected feature count\")\n",
        "        errcount += 1\n",
        "    if 'weighted avg' not in result:\n",
        "        print(f\"Error for `{assessfunc.__name__}`: Unexpected return value\")\n",
        "        errcount += 1\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{assessfunc.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEznstWsBg_a",
        "outputId": "4afe3404-bccd-4462-8e6a-759758d53388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `assess_linear_model`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "test_assess_linear_model(assess_linear_model, train_linear_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6JWZ8tgBg_a"
      },
      "source": [
        "If you trained a model `lr_unigrams` above, you can now easily assess it. An example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buRd2jpYJ8hR",
        "outputId": "d6f9b7e0-5102-4e8a-9699-8cbc1ffc8667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.37      0.49      1200\n",
            "     neutral       0.52      0.89      0.66      1200\n",
            "    positive       0.70      0.57      0.63      1200\n",
            "\n",
            "    accuracy                           0.61      3600\n",
            "   macro avg       0.66      0.61      0.59      3600\n",
            "weighted avg       0.66      0.61      0.59      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = assess_linear_model(\n",
        "    lr_unigrams,\n",
        "    unigrams_phi,\n",
        "    vec_unigrams,\n",
        "    dynasent_r1['validation'])\n",
        "\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezZAgHCNJ8hS"
      },
      "source": [
        "## Question 2: Transformer fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLR-4yyfBg_b"
      },
      "source": [
        "We're now going to move into a more modern mode: fine-tuning pretrained components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnE42J1pBg_b"
      },
      "source": [
        "We'll use BERT-mini (originally from [the BERT repo](https://github.com/google-research/bert)) for the homework so that we can rapdily develop prototypes. You can then consider scaling up to larger models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "1e6243a88f25450b81aaad1c05dc949a",
            "35390e83121046a1bd444a6441f8b906",
            "996fa992ef394f80882110cefc0a23e0",
            "fea320223da84423a8db6b5e549ce355",
            "e859edb5f7324731906c37d5e2eed1d0",
            "2b221952b8d442d89192096f9855df3a",
            "1772452d977d41c9a81188168df04869",
            "75bfba1c4c8e4d8faf11b1e9af954fc6",
            "40fd40543136430ea7c99d44fb2a6c40",
            "f3e71dc20f1345ff8b6c4f13069627dd",
            "90e326aa04ea4b069d5fe66d84a2b010"
          ]
        },
        "id": "snFa5OWHBg_c",
        "outputId": "c64a6993-c7b8-4489-a7c1-fd426a952fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e6243a88f25450b81aaad1c05dc949a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XMEy5HABg_c"
      },
      "source": [
        "The `transformers` library does a lot of logging. To avoid ending up with a cluttered notebook, I am changing the logging level. You might want to skip this as you scale up to building production systems, since the logging is very good – it gives you a lot of insights into what the models and code are doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gIFayUKLBg_c"
      },
      "outputs": [],
      "source": [
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mES-_rWYBg_d"
      },
      "source": [
        "Here we set ourselves up to use BERT-mini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1aabdd6d94d9481191241452c60d4f3f",
            "db9144055378466785fa596c93545417",
            "d02fe2131bff422b80fe574cd193c474",
            "c8f0ffd6cec44c268d4860d161118f07",
            "60ec4595dab74923912e96399a731c22",
            "45f5c46582f542dfa0ae5933373a787f",
            "46116c1bd3dd49d89ac51ab491f75cc6",
            "0e1d8c045ebb43b2a5b79eb2c9227a6d",
            "64a38ef104e1423e8bf54e04916b69da",
            "f558c1dc810e4978a9768604a4c277a7",
            "59564e62791a4c7885c65d8e40e95d5a"
          ]
        },
        "id": "19wOvLkUBg_d",
        "outputId": "730b5f2a-6998-466a-e27a-b137a250a0c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aabdd6d94d9481191241452c60d4f3f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "weights_name = \"prajjwal1/bert-mini\"\n",
        "\n",
        "bert = AutoModel.from_pretrained(weights_name)\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(weights_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nscc7NSBg_d"
      },
      "source": [
        "### Background: Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4eDEVpOBg_d"
      },
      "source": [
        "Tokenization in Transformer models is handled differently from tokenization in linear models of the sort we used in Question 1. For Transformer models, we need to use the tokenizer that comes with the model so that we reliably have embedding representations for every token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "DaLDdApDBg_d"
      },
      "outputs": [],
      "source": [
        "example_text = \"Bert knows Snuffleupagus\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w_QTcQhBg_e"
      },
      "source": [
        "Here's a basic tokenization step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mpqyzVPBg_e",
        "outputId": "68c59de0-7de7-4e60-b7d5-0c8f57160013"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert', 'knows', 's', '##nu', '##ffle', '##up', '##ag', '##us']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "bert_tokenizer.tokenize(example_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASvp4nFjBg_e"
      },
      "source": [
        "Notice that the tokenizer split \"Snuffleupagus\" into a bunch of subword tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-jmlciUBg_e"
      },
      "source": [
        "The above use of the tokenizer, where we map from strings to lists of strings, is really for us humans. For modeling, the most important step for tokenization is mapping individual strings to sequences of integer ids. These ids key into the lowest embedding layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws12DwiHBg_e",
        "outputId": "9c8a8524-6ead-42d4-ac6a-a78d267702cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 14324, 4282, 1055, 11231, 18142, 6279, 8490, 2271, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "ex_ids = bert_tokenizer.encode(example_text, add_special_tokens=True)\n",
        "\n",
        "ex_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-h0JtUzBg_e"
      },
      "source": [
        "We can get map these indices back to \"words\" if we want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVPGyCy6Bg_e",
        "outputId": "50cde952-ff16-4a67-b548-0a17b19021ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'bert',\n",
              " 'knows',\n",
              " 's',\n",
              " '##nu',\n",
              " '##ffle',\n",
              " '##up',\n",
              " '##ag',\n",
              " '##us',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "bert_tokenizer.convert_ids_to_tokens(ex_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOFuhXm6Bg_f"
      },
      "source": [
        "### Background: Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSe6y4PMBg_f"
      },
      "source": [
        "Having mapped our string to a list of tokens, we can use the `forward` method of the model to get representations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "85ihVlL-Bg_f"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaxUwFtNBg_f"
      },
      "source": [
        "There are a lot of options for which representations to get. With the above call, we got the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZdQF3CQBg_f",
        "outputId": "af22448c-a7b5-4fff-83cf-b5a692684097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "reps.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_N4fUIpBg_f"
      },
      "source": [
        "The value of `last_hidden_state` hidden state is the sequence of final output states from the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5mKvae_Bg_f",
        "outputId": "a00136c6-70e5-4a72-9383-1171019fabe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "reps.last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WivZMXzBg_g"
      },
      "source": [
        "This is: 1 example, 10 token representations, each one a 256 dimension vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8tFLxA1Bg_g"
      },
      "source": [
        "The value of `pooler_output` is a set of currently random parameters sitting on top of the first output hidden state. You can see here that it is a single vector representation per example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdig2TeBg_g",
        "outputId": "424fe026-7b29-488b-89a7-12f44a970a8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "reps.pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfTW2US7Bg_g"
      },
      "source": [
        "I often feel unsure of precisely what this model component is. Here we can have a quick look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vULybCkTBg_g",
        "outputId": "0fd64ac0-e786-4ec8-b423-6ef803b43284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "bert.pooler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n81S-eG5Bg_g"
      },
      "source": [
        "So this is a dense linear layer (a single matrix of weights) with a bias term, and a tanh activation function is applied to the output. We could put a classifier head on top of this if we wanted to, but we might have mixed feelings about being stuck with that tanh step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjMwWkLlBg_g"
      },
      "source": [
        "### Background: Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vpW1bdNBg_g"
      },
      "source": [
        "Where examples from a single batch have different lengths, we need to mask the padded tokens to get the intended results from the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SdY8UwqBg_h"
      },
      "source": [
        "For a quick example, here we process our full example from above and print out the first five values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg8ZoqlXBg_h",
        "outputId": "f4a2d215-6bbe-40d0-a2ba-e88b35ca6442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3763, -0.3209,  0.8817,  0.4568, -1.0314])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    reps = bert(torch.tensor([ex_ids]))\n",
        "    print(reps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfCBBgyUBg_h"
      },
      "source": [
        "And now we do the same thing, but with masking of the final five positions to illustate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWvoXV-SBg_h",
        "outputId": "595847ad-73f1-482a-887d-cfce7531f228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1793, -0.8994,  0.9695,  0.9130, -0.7129])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    # Mask the last 5 tokens:\n",
        "    am = torch.tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n",
        "    maskreps = bert(torch.tensor([ex_ids]), attention_mask=am)\n",
        "    print(maskreps.last_hidden_state[0][0][: 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0DMKoU8Bg_h"
      },
      "source": [
        "### Task 1: Batch tokenization [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDcnAXS8Bg_h"
      },
      "source": [
        "Your task here is to use the `batch_encode_plus` method for `bert_tokenizer` to tokenize a list of strings. You should complete `get_batch_token_ids` according to the specification in the doctring. All these steps can be handled with a single call to `batch_encode_plus`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "E9Bj4yxABg_i"
      },
      "outputs": [],
      "source": [
        "def get_batch_token_ids(batch, tokenizer):\n",
        "    \"\"\"Map `batch` to a tensor of ids. The return\n",
        "    value should meet the following specification:\n",
        "\n",
        "    1. The max length should be 512.\n",
        "    2. Examples longer than the max length should be truncated\n",
        "    3. Examples should be padded to the max length for the batch.\n",
        "    4. The special [CLS] should be added to the start and the special\n",
        "       token [SEP] should be added to the end.\n",
        "    5. The attention mask should be returned\n",
        "    6. The return value of each component should be a tensor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch: list of str\n",
        "    tokenizer: Hugging Face tokenizer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict with at least \"input_ids\" and \"attention_mask\" as keys,\n",
        "    each with Tensor values\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "    result = tokenizer.batch_encode_plus(\n",
        "        batch,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt')\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANnFm99GBg_i"
      },
      "source": [
        "Here's a test you can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "C30fQRGEBg_i"
      },
      "outputs": [],
      "source": [
        "def test_get_batch_token_ids(func):\n",
        "    examples = [\n",
        "        \"Bert knows Snuffleupagus\",\n",
        "        \"ELMo knew Bert.\",\n",
        "        \"Buffalo \" * 520\n",
        "    ]\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-mini\")\n",
        "    result = func(examples, test_tokenizer)\n",
        "    errcount = 0\n",
        "    if 'attention_mask' not in result:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Attention mask was not returned\")\n",
        "    ids = result['input_ids']\n",
        "    if not isinstance(ids, torch.Tensor):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Return values are not tensors\")\n",
        "    if ids.shape[1] != 512:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected sequence length 512; got {ids.shape[1]}\")\n",
        "    if ids[0][0] != bert_tokenizer.cls_token_id:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Special tokens were not added\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdsBd5dFBg_i",
        "outputId": "32fd03a1-60f2-47e6-8bec-da475edd7e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_batch_token_ids`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "test_get_batch_token_ids(get_batch_token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehfJG-iwBg_i"
      },
      "source": [
        "### Task 2: Contextual representations [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEZVeOFgBg_i"
      },
      "source": [
        "This next task is not used directly in fine-tuning, but it should help ensure that you understand how BERT representations are created and how they need to be managed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCyErxQ0Bg_i"
      },
      "source": [
        "Your task is to complete `get_reps` so that, given a dataset (list of strings), it returns a single tensor in which each row is the output hidden state above the [CLS] token for that example. `gets_reps` has a batchsize argument that the user can manage depending on how much available memory they have and how large their model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SEDdTZALBg_i"
      },
      "outputs": [],
      "source": [
        "def get_reps(dataset, model, tokenizer, batchsize=20):\n",
        "    \"\"\"Represent each example in `dataset` with the final hidden state\n",
        "    above the [CLS] token.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : list of str\n",
        "    model : BertModel\n",
        "    tokenizer : BertTokenizerFast\n",
        "    batchsize : int\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor with shape `(n_examples, dim)` where `dim` is the\n",
        "    dimensionality of the representations for `model`\n",
        "\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with torch.no_grad():\n",
        "        pass\n",
        "        # Iterate over `dataset` in batches:\n",
        "        ##### YOUR CODE HERE\n",
        "        for id in range(0, len(dataset), batchsize):\n",
        "            batch = dataset[id: id + batchsize]\n",
        "\n",
        "            # Encode the batch with `get_batch_token_ids`:\n",
        "            ##### YOUR CODE HERE\n",
        "            batch_ids = get_batch_token_ids(batch, tokenizer)\n",
        "            token_ids = batch_ids['input_ids']\n",
        "            attention_mask = batch_ids['attention_mask']\n",
        "\n",
        "            # Get the representations from the model, making\n",
        "            # sure to pay attention to masking:\n",
        "            ##### YOUR CODE HERE\n",
        "            mask_reps = model(token_ids, attention_mask=attention_mask)\n",
        "            data.append(mask_reps.last_hidden_state[:, 0, :])\n",
        "\n",
        "        # Return a single tensor:\n",
        "        ##### YOUR CODE HERE\n",
        "    return torch.cat(data, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQ1cToPBg_j"
      },
      "source": [
        "Quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GRZHAzOZBg_j"
      },
      "outputs": [],
      "source": [
        "def test_get_reps(func):\n",
        "    examples = [\"The cat slept.\", \"The bird chirped.\"] * 20\n",
        "    weights_name = \"prajjwal1/bert-mini\"\n",
        "    test_model = AutoModel.from_pretrained(weights_name)\n",
        "    test_tokenizer = AutoTokenizer.from_pretrained(weights_name)\n",
        "    result = func(examples, test_model, test_tokenizer, batchsize=2)\n",
        "    errcount = 0\n",
        "    if result.shape != (40, 256):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Expected shape {(40, 256)}, got {result.shape}\")\n",
        "    if round(result[0][0].item(), 2) != -0.64:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "              f\"Representations seem to be incorrect\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqMzTOYLBg_j",
        "outputId": "abffbdb5-e7d4-4a7c-d993-1de1bb822daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `get_reps`\n"
          ]
        }
      ],
      "source": [
        "test_get_reps(get_reps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORXMK8tmBg_j"
      },
      "source": [
        "### Task 3: Fine-tuning module [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNy_xz6pBg_j"
      },
      "source": [
        "We can now put the above together into a basic `nn.Module` that will fine-tune our BERT model. Most of the module is written for you. The pieces you need to implement:\n",
        "\n",
        "1. in the `init` methid, define `self.classifier_layer` using [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "2. Complete the `forward` method.\n",
        "\n",
        "Precise instructions are provided in the docstrings for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "DI_llzyUJ8hS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BertClassifierModule(nn.Module):\n",
        "    def __init__(self,\n",
        "            n_classes,\n",
        "            hidden_activation,\n",
        "            weights_name=\"prajjwal1/bert-mini\"):\n",
        "        \"\"\"This module loads a Transformer based on  `weights_name`,\n",
        "        puts it in train mode, add a dense layer with activation\n",
        "        function give by `hidden_activation`, and puts a classifier\n",
        "        layer on top of that as the final output. The output of\n",
        "        the dense layer should have the same dimensionality as the\n",
        "        model input.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_classes : int\n",
        "            Number of classes for the output layer\n",
        "        hidden_activation : torch activation function\n",
        "            e.g., nn.Tanh()\n",
        "        weights_name : str\n",
        "            Name of pretrained model to load from Hugging Face\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.weights_name = weights_name\n",
        "        self.bert = AutoModel.from_pretrained(self.weights_name)\n",
        "        self.bert.train()\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.hidden_dim = self.bert.embeddings.word_embeddings.embedding_dim\n",
        "        # Add the new parameters here using `nn.Sequential`.\n",
        "        # We can define this layer as\n",
        "        #\n",
        "        #  h = f(cW1 + b_h)\n",
        "        #  y = hW2 + b_y\n",
        "        #\n",
        "        # where c is the final hidden state above the [CLS] token,\n",
        "        # W1 has dimensionality (self.hidden_dim, self.hidden_dim),\n",
        "        # W2 has dimensionality (self.hidden_dim, self.n_classes),\n",
        "        # f is the hidden activation, and we rely on the PyTorch loss\n",
        "        # function to add apply a softmax to y.\n",
        "        self.classifier_layer = None\n",
        "        ##### YOUR CODE HERE\n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=True),\n",
        "            self.hidden_activation,\n",
        "            nn.Linear(self.hidden_dim, self.n_classes, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, indices, mask):\n",
        "        \"\"\"Process `indices` with `mask` by feeding these arguments\n",
        "        to `self.bert` and then feeding the initial hidden state\n",
        "        in `last_hidden_state` to `self.classifier_layer`\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        indices : tensor.LongTensor of shape (n_batch, k)\n",
        "            Indices into the `self.bert` embedding layer. `n_batch` is\n",
        "            the number of examples and `k` is the sequence length for\n",
        "            this batch\n",
        "        mask : tensor.LongTensor of shape (n_batch, d)\n",
        "            Binary vector indicating which values should be masked.\n",
        "            `n_batch` is the number of examples and `k` is the\n",
        "            sequence length for this batch\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tensor.FloatTensor\n",
        "            Predicted values, shape `(n_batch, self.n_classes)`\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "        ##### YOUR CODE HERE\n",
        "        reps = self.bert(indices, attention_mask=mask)\n",
        "        logits = self.classifier_layer(reps.last_hidden_state[:, 0, :].squeeze(1))\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "17bb4e1e1ff14b38ae6142f8ead9fbb3",
            "8de8bdeca1d04233895879ddff60f6d2",
            "98d04f76302e404c83c388596a3edba8",
            "cc9cea8864b6412f980df8c54eb73e2c",
            "eaf1c6c799934b648ad515679a50ac75",
            "50c5169b8f284e87b0df25f029695618",
            "e7e7e729eb394d29899274fd3f4dda28",
            "52cb92f3e28546c185e0ce3f375bbfb8",
            "37d871d5c8954107b7b665a1d5392466",
            "df6b29023444474d861f737ccc0ccf6d",
            "689af9ee71354759a8bfecbcb16faa8f",
            "6c413f7e38a849feab94f3737bcae2b4",
            "b07a23b664624fd4b9124f263fcdd819",
            "1443b006e5be4293851fc653d3434a25",
            "f1f1157d0c774a548d749d6eee4ac75b",
            "f8608f815c2d48dd8ca6e3d8901478cf",
            "552a1aaa8e0e4f4199427be97b01ad65",
            "e710fe909d1c41fbb014bd2801b70a99",
            "32add54b04bf4dcf85b7c877509fb1d1",
            "72751587839f41c2aa8cbbe1c56c9ea7",
            "9ed1543eaa9f445eb024da2be3758a33",
            "2c9130ccb0844d86aa4188cbfed8eb45"
          ]
        },
        "id": "V7xkh5zEBg_j",
        "outputId": "3dcd0566-82be-4959-82b1-0d8d2e4f9ccf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17bb4e1e1ff14b38ae6142f8ead9fbb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c413f7e38a849feab94f3737bcae2b4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_module = BertClassifierModule(n_classes=3, hidden_activation=nn.Tanh())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5u_U-UiBg_k",
        "outputId": "3af18fac-b99e-49b4-f86d-49fc9ddc6de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0176,  0.3444, -0.2641],\n",
              "        [ 0.1435,  0.4630,  0.0083]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "ids = get_batch_token_ids(\n",
        "    dynasent_r1['train']['sentence'][: 2],\n",
        "    bert_tokenizer)\n",
        "\n",
        "bert_module(ids['input_ids'], ids['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bR5_3LI1Bg_k"
      },
      "outputs": [],
      "source": [
        "def test_bert_classifier_module(moduleclass):\n",
        "    expected_out = 5\n",
        "    expected_hidden = 256\n",
        "    expected_activation = nn.ReLU()\n",
        "    mod = moduleclass(expected_out, expected_activation)\n",
        "    errcount = 0\n",
        "\n",
        "    # Basic layer structure:\n",
        "    if not hasattr(mod, \"classifier_layer\") or mod.classifier_layer is None:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Missing attribute `classifier_layer`\")\n",
        "        return\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            bert_module.classifier_layer[i]\n",
        "        except IndexError:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "                  f\"`classifier_layer` is not an `nn.Sequential` \"\n",
        "                  f\"and/or does not have the right structure\")\n",
        "    # Correct first layer dimensionality:\n",
        "    result_hidden = mod.classifier_layer[0].out_features\n",
        "    if result_hidden != expected_hidden:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` hidden dim {expected_hidden}, \"\n",
        "              f\"got {result_hidden}\")\n",
        "    # Correct activation:\n",
        "    result_activation = mod.classifier_layer[1].__class__.__name__\n",
        "    if result_activation != expected_activation.__class__.__name__:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Incorrect hidden activation\")\n",
        "    # Correct output dimensionality:\n",
        "    result_out = mod.classifier_layer[2].out_features\n",
        "    if result_out != expected_out:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected `classifier_layer` out dim {expected_out}, \"\n",
        "              f\"got {result_out}\")\n",
        "    # forward method:\n",
        "    ids = get_batch_token_ids([\"A B C\", \"A B\"], bert_tokenizer)\n",
        "    result = mod(ids['input_ids'], ids['attention_mask'])\n",
        "    if result.shape != (2, 5):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{moduleclass.__name__}`: \"\n",
        "              f\"Expected output shape {(2, 5)}, got {result.shape}\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors found for `{moduleclass.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cui7O9CBg_k",
        "outputId": "e687ab42-7baa-45d4-822d-05d28e20ebf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found for `BertClassifierModule`\n"
          ]
        }
      ],
      "source": [
        "test_bert_classifier_module(BertClassifierModule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohudEKFKBg_k"
      },
      "source": [
        "### Optional use: Classifier interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBPICVG7Bg_k"
      },
      "source": [
        "The above module doesn't have functionality for processing data and fitting models. Our course code includes some general purpose code for adding these features. Here is an example that should work well with the module you wrote above. For more details on the design of these interfaces, see [tutorial_pytorch_models.ipynb](tutorial_pytorch_models.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rfD8yC4AJ8hT"
      },
      "outputs": [],
      "source": [
        "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
        "\n",
        "class BertClassifier(TorchShallowNeuralClassifier):\n",
        "    def __init__(self, weights_name, *args, **kwargs):\n",
        "        self.weights_name = weights_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.weights_name)\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.params += ['weights_name']\n",
        "\n",
        "    def build_graph(self):\n",
        "        return BertClassifierModule(\n",
        "            self.n_classes_, self.hidden_activation, self.weights_name)\n",
        "\n",
        "    def build_dataset(self, X, y=None):\n",
        "        data = get_batch_token_ids(X, self.tokenizer)\n",
        "        if y is None:\n",
        "            dataset = torch.utils.data.TensorDataset(\n",
        "                data['input_ids'], data['attention_mask'])\n",
        "        else:\n",
        "            self.classes_ = sorted(set(y))\n",
        "            self.n_classes_ = len(self.classes_)\n",
        "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
        "            y = [class2index[label] for label in y]\n",
        "            y = torch.tensor(y)\n",
        "            dataset = torch.utils.data.TensorDataset(\n",
        "                data['input_ids'], data['attention_mask'], y)\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwqYPqYBg_l"
      },
      "source": [
        "And here is a training run that should do pretty well for our problem.\n",
        "\n",
        "__Note__: This step should not be run on CPU machines. On Google Colab with a GPU, it will likely take about an hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "re8lzSepJ8hT"
      },
      "outputs": [],
      "source": [
        "bert_finetune = BertClassifier(\n",
        "    weights_name=\"prajjwal1/bert-mini\",\n",
        "    hidden_activation=nn.ReLU(),\n",
        "    eta=0.00005,          # Low learning rate for effective fine-tuning.\n",
        "    batch_size=8,         # Small batches to avoid memory overload.\n",
        "    gradient_accumulation_steps=4,  # Increase the effective batch size to 32.\n",
        "    early_stopping=True,  # Early-stopping\n",
        "    n_iter_no_change=5)   # params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlvq0G-PJ8hT",
        "outputId": "fb522598-fd71-47c3-b871-c92f66061dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finished epoch 1 of 1000; error is 1700.4712700657547/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 2 of 1000; error is 1465.8463959433138/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 3 of 1000; error is 1308.3391571333632/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 4 of 1000; error is 1171.3988110879436/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 5 of 1000; error is 1031.1641239812598/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 6 of 1000; error is 908.7538340627216/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 7 of 1000; error is 797.1124854263617/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 8 of 1000; error is 695.030571274343/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Finished epoch 9 of 1000; error is 606.8326550390339/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Stopping after epoch 10. Validation score did not improve by tol=1e-05 for more than 5 epochs. Final error is 545.4015271529788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1h 14min 24s, sys: 19.5 s, total: 1h 14min 43s\n",
            "Wall time: 1h 14min 14s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "_ = bert_finetune.fit(\n",
        "    dynasent_r1['train']['sentence'],\n",
        "    dynasent_r1['train']['gold_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "WwwiIuKqJ8hT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3be6f7d-0965-4786-f9cd-cd1c3d038249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "preds = bert_finetune.predict(sst['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Af7RAOJ8hT",
        "outputId": "fb44a291-6c94-4335-e9dc-0007f7c4ba7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.602     0.533     0.565       428\n",
            "     neutral      0.316     0.389     0.348       229\n",
            "    positive      0.627     0.622     0.624       444\n",
            "\n",
            "    accuracy                          0.539      1101\n",
            "   macro avg      0.515     0.514     0.513      1101\n",
            "weighted avg      0.552     0.539     0.544      1101\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(sst['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "YOblLwl3J8hU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4bbb61-f525-4158-b48c-6f038905be74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "preds = bert_finetune.predict(dynasent_r1['validation']['sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndDbPLY1b7lj",
        "outputId": "9042746b-7c37-4c3d-9c8f-362a8534c12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.804     0.530     0.639      1200\n",
            "     neutral      0.612     0.897     0.728      1200\n",
            "    positive      0.764     0.669     0.713      1200\n",
            "\n",
            "    accuracy                          0.699      3600\n",
            "   macro avg      0.727     0.699     0.693      3600\n",
            "weighted avg      0.727     0.699     0.693      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(dynasent_r1['validation']['gold_label'], preds, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xcl3KQXBg_m"
      },
      "source": [
        "## Question 3: Your original system [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQSfNUQCBg_m"
      },
      "source": [
        "Your task is to develop an original ternary sentiment classifier model. There are many options. The only rule:\n",
        "\n",
        "__You cannot make any use of the test sets for DynaSent-R1, DynaSent-R2, or SST-3, at any time during the course of development.__\n",
        "\n",
        "The integrity of the bakeoff depends on this rule being followed.\n",
        "\n",
        "It's fine to use the dev sets for system development – indeed, we encourage this.\n",
        "\n",
        "For system development, here are some relatively manageable ideas that you might try:\n",
        "\n",
        "* Different pretrained models. There are many models available on the [Hugging Face models hub](https://huggingface.co/models) that will be drop-in replacements for BERT-mini as we used it above.\n",
        "\n",
        "* Different fine-tuning regimes. We used the [CLS] token above. This doesn't make especially good use of the output states of the models. Pooling across these representtions (with sum, average, etc.) is likely to be better.\n",
        "\n",
        "* Different training regimes. You have three train sets at your disposal, and there may be other sentiment datasets that could contribute to making your system more robust in new domains.\n",
        "\n",
        "* Entirely different approaches. There is no requirement that you make use of any of the concepts from the homework questions in constructing your original system. Anything goes as long as you follow the one rule given above in bold.\n",
        "\n",
        "We want to emphasize that this needs to be an original system. It doesn't suffice to download code from the Web, retrain, and submit. You can build on others' code, but you have to do something new and meaningful with it. See the course website for additional guidance on how original systems will be evaluated.\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myAeTjyeBg_m",
        "outputId": "d961c706-49d5-4218-d812-5598a587570a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-39-e20887f7bc79>:105: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.0499, 'grad_norm': 4.859266757965088, 'learning_rate': 1.996024647187438e-05, 'epoch': 0.0009939369843951894}\n",
            "{'loss': 1.002, 'grad_norm': 4.51099967956543, 'learning_rate': 1.992049294374876e-05, 'epoch': 0.001987873968790379}\n",
            "{'loss': 0.8744, 'grad_norm': 7.18701696395874, 'learning_rate': 1.9880739415623137e-05, 'epoch': 0.002981810953185568}\n",
            "{'loss': 0.9735, 'grad_norm': 13.22158145904541, 'learning_rate': 1.9840985887497518e-05, 'epoch': 0.003975747937580758}\n",
            "{'loss': 0.8804, 'grad_norm': 4.386469841003418, 'learning_rate': 1.9801232359371895e-05, 'epoch': 0.004969684921975946}\n",
            "{'loss': 0.9882, 'grad_norm': 3.1850223541259766, 'learning_rate': 1.9761478831246276e-05, 'epoch': 0.005963621906371136}\n",
            "{'loss': 0.9288, 'grad_norm': 4.637726783752441, 'learning_rate': 1.9721725303120653e-05, 'epoch': 0.006957558890766325}\n",
            "{'loss': 0.9265, 'grad_norm': 7.020766258239746, 'learning_rate': 1.968197177499503e-05, 'epoch': 0.007951495875161516}\n",
            "{'loss': 1.0276, 'grad_norm': 14.550045013427734, 'learning_rate': 1.964221824686941e-05, 'epoch': 0.008945432859556703}\n",
            "{'loss': 1.0694, 'grad_norm': 6.3808746337890625, 'learning_rate': 1.960246471874379e-05, 'epoch': 0.009939369843951893}\n",
            "{'loss': 1.0118, 'grad_norm': 9.294602394104004, 'learning_rate': 1.956271119061817e-05, 'epoch': 0.010933306828347082}\n",
            "{'loss': 1.0331, 'grad_norm': 4.769899368286133, 'learning_rate': 1.9522957662492547e-05, 'epoch': 0.011927243812742272}\n",
            "{'loss': 0.9437, 'grad_norm': 12.802901268005371, 'learning_rate': 1.9483204134366928e-05, 'epoch': 0.012921180797137461}\n",
            "{'loss': 0.9958, 'grad_norm': 9.757179260253906, 'learning_rate': 1.9443450606241305e-05, 'epoch': 0.01391511778153265}\n",
            "{'loss': 1.0054, 'grad_norm': 23.04378890991211, 'learning_rate': 1.9403697078115683e-05, 'epoch': 0.01490905476592784}\n",
            "{'loss': 0.9221, 'grad_norm': 11.793482780456543, 'learning_rate': 1.9363943549990063e-05, 'epoch': 0.01590299175032303}\n",
            "{'loss': 0.8701, 'grad_norm': 20.713382720947266, 'learning_rate': 1.932419002186444e-05, 'epoch': 0.01689692873471822}\n",
            "{'loss': 0.831, 'grad_norm': 14.62730598449707, 'learning_rate': 1.928443649373882e-05, 'epoch': 0.017890865719113407}\n",
            "{'loss': 0.9729, 'grad_norm': 22.078067779541016, 'learning_rate': 1.92446829656132e-05, 'epoch': 0.018884802703508598}\n",
            "{'loss': 0.8721, 'grad_norm': 14.4830904006958, 'learning_rate': 1.920492943748758e-05, 'epoch': 0.019878739687903785}\n",
            "{'loss': 0.7088, 'grad_norm': 10.554306030273438, 'learning_rate': 1.9165175909361957e-05, 'epoch': 0.020872676672298977}\n",
            "{'loss': 0.873, 'grad_norm': 15.210501670837402, 'learning_rate': 1.9125422381236335e-05, 'epoch': 0.021866613656694164}\n",
            "{'loss': 0.9532, 'grad_norm': 11.465020179748535, 'learning_rate': 1.9085668853110715e-05, 'epoch': 0.022860550641089356}\n",
            "{'loss': 0.7638, 'grad_norm': 18.284847259521484, 'learning_rate': 1.9045915324985093e-05, 'epoch': 0.023854487625484543}\n",
            "{'loss': 0.7507, 'grad_norm': 23.46649169921875, 'learning_rate': 1.9006161796859473e-05, 'epoch': 0.024848424609879734}\n",
            "{'loss': 0.7159, 'grad_norm': 19.608570098876953, 'learning_rate': 1.896640826873385e-05, 'epoch': 0.025842361594274922}\n",
            "{'loss': 0.7446, 'grad_norm': 14.129871368408203, 'learning_rate': 1.892665474060823e-05, 'epoch': 0.026836298578670113}\n",
            "{'loss': 0.6524, 'grad_norm': 19.96803092956543, 'learning_rate': 1.888690121248261e-05, 'epoch': 0.0278302355630653}\n",
            "{'loss': 0.6627, 'grad_norm': 18.003808975219727, 'learning_rate': 1.8847147684356986e-05, 'epoch': 0.028824172547460492}\n",
            "{'loss': 0.7952, 'grad_norm': 20.826881408691406, 'learning_rate': 1.8807394156231367e-05, 'epoch': 0.02981810953185568}\n",
            "{'loss': 0.6954, 'grad_norm': 19.012304306030273, 'learning_rate': 1.8767640628105745e-05, 'epoch': 0.03081204651625087}\n",
            "{'loss': 0.7663, 'grad_norm': 21.60076904296875, 'learning_rate': 1.8727887099980125e-05, 'epoch': 0.03180598350064606}\n",
            "{'loss': 0.6529, 'grad_norm': 20.272865295410156, 'learning_rate': 1.8688133571854503e-05, 'epoch': 0.032799920485041247}\n",
            "{'loss': 0.7347, 'grad_norm': 29.13750457763672, 'learning_rate': 1.8648380043728883e-05, 'epoch': 0.03379385746943644}\n",
            "{'loss': 0.7494, 'grad_norm': 16.523923873901367, 'learning_rate': 1.860862651560326e-05, 'epoch': 0.03478779445383163}\n",
            "{'loss': 0.8021, 'grad_norm': 41.36110305786133, 'learning_rate': 1.8568872987477638e-05, 'epoch': 0.03578173143822681}\n",
            "{'loss': 0.8503, 'grad_norm': 26.47657012939453, 'learning_rate': 1.852911945935202e-05, 'epoch': 0.036775668422622004}\n",
            "{'loss': 0.6341, 'grad_norm': 42.14063262939453, 'learning_rate': 1.8489365931226396e-05, 'epoch': 0.037769605407017195}\n",
            "{'loss': 0.7028, 'grad_norm': 39.5946159362793, 'learning_rate': 1.8449612403100777e-05, 'epoch': 0.03876354239141239}\n",
            "{'loss': 0.5799, 'grad_norm': 9.555502891540527, 'learning_rate': 1.8409858874975155e-05, 'epoch': 0.03975747937580757}\n",
            "{'loss': 0.6554, 'grad_norm': 37.55560302734375, 'learning_rate': 1.8370105346849535e-05, 'epoch': 0.04075141636020276}\n",
            "{'loss': 0.7892, 'grad_norm': 21.868633270263672, 'learning_rate': 1.8330351818723913e-05, 'epoch': 0.04174535334459795}\n",
            "{'loss': 0.6628, 'grad_norm': 13.65584659576416, 'learning_rate': 1.829059829059829e-05, 'epoch': 0.042739290328993144}\n",
            "{'loss': 0.626, 'grad_norm': 44.26200866699219, 'learning_rate': 1.825084476247267e-05, 'epoch': 0.04373322731338833}\n",
            "{'loss': 0.7195, 'grad_norm': 32.205543518066406, 'learning_rate': 1.8211091234347048e-05, 'epoch': 0.04472716429778352}\n",
            "{'loss': 0.6833, 'grad_norm': 24.154827117919922, 'learning_rate': 1.817133770622143e-05, 'epoch': 0.04572110128217871}\n",
            "{'loss': 0.8244, 'grad_norm': 30.99809455871582, 'learning_rate': 1.8131584178095806e-05, 'epoch': 0.0467150382665739}\n",
            "{'loss': 0.784, 'grad_norm': 23.37335205078125, 'learning_rate': 1.8091830649970187e-05, 'epoch': 0.047708975250969086}\n",
            "{'loss': 0.7737, 'grad_norm': 12.875360488891602, 'learning_rate': 1.8052077121844565e-05, 'epoch': 0.04870291223536428}\n",
            "{'loss': 0.7459, 'grad_norm': 19.514307022094727, 'learning_rate': 1.8012323593718942e-05, 'epoch': 0.04969684921975947}\n",
            "{'loss': 0.6815, 'grad_norm': 9.704133033752441, 'learning_rate': 1.7972570065593323e-05, 'epoch': 0.05069078620415466}\n",
            "{'loss': 0.7617, 'grad_norm': 25.796606063842773, 'learning_rate': 1.79328165374677e-05, 'epoch': 0.051684723188549844}\n",
            "{'loss': 0.7037, 'grad_norm': 18.47344970703125, 'learning_rate': 1.789306300934208e-05, 'epoch': 0.052678660172945035}\n",
            "{'loss': 0.7804, 'grad_norm': 37.18837356567383, 'learning_rate': 1.7853309481216458e-05, 'epoch': 0.05367259715734023}\n",
            "{'loss': 0.7007, 'grad_norm': 8.465755462646484, 'learning_rate': 1.781355595309084e-05, 'epoch': 0.05466653414173541}\n",
            "{'loss': 0.7712, 'grad_norm': 7.74869966506958, 'learning_rate': 1.7773802424965216e-05, 'epoch': 0.0556604711261306}\n",
            "{'loss': 0.7066, 'grad_norm': 10.886955261230469, 'learning_rate': 1.7734048896839594e-05, 'epoch': 0.05665440811052579}\n",
            "{'loss': 0.6084, 'grad_norm': 8.895938873291016, 'learning_rate': 1.7694295368713975e-05, 'epoch': 0.057648345094920984}\n",
            "{'loss': 0.6491, 'grad_norm': 15.89396858215332, 'learning_rate': 1.7654541840588352e-05, 'epoch': 0.05864228207931617}\n",
            "{'loss': 0.6364, 'grad_norm': 15.481428146362305, 'learning_rate': 1.7614788312462733e-05, 'epoch': 0.05963621906371136}\n",
            "{'loss': 0.7032, 'grad_norm': 38.97602081298828, 'learning_rate': 1.757503478433711e-05, 'epoch': 0.06063015604810655}\n",
            "{'loss': 0.6981, 'grad_norm': 22.16902732849121, 'learning_rate': 1.753528125621149e-05, 'epoch': 0.06162409303250174}\n",
            "{'loss': 0.7966, 'grad_norm': 21.41120719909668, 'learning_rate': 1.7495527728085868e-05, 'epoch': 0.06261803001689693}\n",
            "{'loss': 0.7484, 'grad_norm': 20.029333114624023, 'learning_rate': 1.7455774199960246e-05, 'epoch': 0.06361196700129212}\n",
            "{'loss': 0.8949, 'grad_norm': 15.263611793518066, 'learning_rate': 1.7416020671834626e-05, 'epoch': 0.0646059039856873}\n",
            "{'loss': 0.7008, 'grad_norm': 21.088027954101562, 'learning_rate': 1.7376267143709004e-05, 'epoch': 0.06559984097008249}\n",
            "{'loss': 0.7358, 'grad_norm': 16.91806983947754, 'learning_rate': 1.7336513615583385e-05, 'epoch': 0.06659377795447768}\n",
            "{'loss': 0.6309, 'grad_norm': 14.21205997467041, 'learning_rate': 1.7296760087457762e-05, 'epoch': 0.06758771493887288}\n",
            "{'loss': 0.6352, 'grad_norm': 29.126502990722656, 'learning_rate': 1.7257006559332143e-05, 'epoch': 0.06858165192326807}\n",
            "{'loss': 0.7474, 'grad_norm': 12.7781400680542, 'learning_rate': 1.721725303120652e-05, 'epoch': 0.06957558890766326}\n",
            "{'loss': 0.6845, 'grad_norm': 10.94996452331543, 'learning_rate': 1.7177499503080897e-05, 'epoch': 0.07056952589205845}\n",
            "{'loss': 0.6662, 'grad_norm': 13.916023254394531, 'learning_rate': 1.7137745974955278e-05, 'epoch': 0.07156346287645363}\n",
            "{'loss': 0.6774, 'grad_norm': 15.154356002807617, 'learning_rate': 1.7097992446829656e-05, 'epoch': 0.07255739986084882}\n",
            "{'loss': 0.6882, 'grad_norm': 17.273191452026367, 'learning_rate': 1.7058238918704036e-05, 'epoch': 0.07355133684524401}\n",
            "{'loss': 0.6769, 'grad_norm': 8.01973819732666, 'learning_rate': 1.7018485390578414e-05, 'epoch': 0.0745452738296392}\n",
            "{'loss': 0.5334, 'grad_norm': 9.207866668701172, 'learning_rate': 1.6978731862452795e-05, 'epoch': 0.07553921081403439}\n",
            "{'loss': 0.8861, 'grad_norm': 24.72518539428711, 'learning_rate': 1.6938978334327172e-05, 'epoch': 0.07653314779842958}\n",
            "{'loss': 0.8899, 'grad_norm': 13.788705825805664, 'learning_rate': 1.689922480620155e-05, 'epoch': 0.07752708478282477}\n",
            "{'loss': 0.6423, 'grad_norm': 11.15209674835205, 'learning_rate': 1.685947127807593e-05, 'epoch': 0.07852102176721996}\n",
            "{'loss': 0.7219, 'grad_norm': 15.28787899017334, 'learning_rate': 1.6819717749950307e-05, 'epoch': 0.07951495875161514}\n",
            "{'loss': 0.6495, 'grad_norm': 20.819883346557617, 'learning_rate': 1.6779964221824688e-05, 'epoch': 0.08050889573601033}\n",
            "{'loss': 0.7404, 'grad_norm': 16.392484664916992, 'learning_rate': 1.674021069369907e-05, 'epoch': 0.08150283272040552}\n",
            "{'loss': 0.7705, 'grad_norm': 14.918435096740723, 'learning_rate': 1.6700457165573446e-05, 'epoch': 0.08249676970480072}\n",
            "{'loss': 0.636, 'grad_norm': 15.299642562866211, 'learning_rate': 1.6660703637447827e-05, 'epoch': 0.0834907066891959}\n",
            "{'loss': 0.5792, 'grad_norm': 11.956501007080078, 'learning_rate': 1.6620950109322205e-05, 'epoch': 0.0844846436735911}\n",
            "{'loss': 0.6105, 'grad_norm': 15.27177906036377, 'learning_rate': 1.6581196581196585e-05, 'epoch': 0.08547858065798629}\n",
            "{'loss': 0.4891, 'grad_norm': 47.34012222290039, 'learning_rate': 1.6541443053070963e-05, 'epoch': 0.08647251764238147}\n",
            "{'loss': 0.6397, 'grad_norm': 13.538460731506348, 'learning_rate': 1.650168952494534e-05, 'epoch': 0.08746645462677666}\n",
            "{'loss': 0.68, 'grad_norm': 18.751047134399414, 'learning_rate': 1.646193599681972e-05, 'epoch': 0.08846039161117185}\n",
            "{'loss': 0.7503, 'grad_norm': 22.240463256835938, 'learning_rate': 1.6422182468694098e-05, 'epoch': 0.08945432859556704}\n",
            "{'loss': 0.6095, 'grad_norm': 10.048095703125, 'learning_rate': 1.638242894056848e-05, 'epoch': 0.09044826557996223}\n",
            "{'loss': 0.7996, 'grad_norm': 19.38571548461914, 'learning_rate': 1.6342675412442856e-05, 'epoch': 0.09144220256435742}\n",
            "{'loss': 0.5632, 'grad_norm': 16.79118537902832, 'learning_rate': 1.6302921884317237e-05, 'epoch': 0.09243613954875261}\n",
            "{'loss': 0.6093, 'grad_norm': 12.979293823242188, 'learning_rate': 1.6263168356191614e-05, 'epoch': 0.0934300765331478}\n",
            "{'loss': 0.8353, 'grad_norm': 32.516353607177734, 'learning_rate': 1.6223414828065992e-05, 'epoch': 0.09442401351754298}\n",
            "{'loss': 0.6396, 'grad_norm': 15.226996421813965, 'learning_rate': 1.6183661299940373e-05, 'epoch': 0.09541795050193817}\n",
            "{'loss': 0.4973, 'grad_norm': 15.974175453186035, 'learning_rate': 1.614390777181475e-05, 'epoch': 0.09641188748633336}\n",
            "{'loss': 0.5841, 'grad_norm': 29.52277946472168, 'learning_rate': 1.610415424368913e-05, 'epoch': 0.09740582447072856}\n",
            "{'loss': 0.6832, 'grad_norm': 43.95949935913086, 'learning_rate': 1.6064400715563508e-05, 'epoch': 0.09839976145512375}\n",
            "{'loss': 0.6977, 'grad_norm': 37.467010498046875, 'learning_rate': 1.602464718743789e-05, 'epoch': 0.09939369843951894}\n",
            "{'loss': 0.5788, 'grad_norm': 21.382627487182617, 'learning_rate': 1.5984893659312266e-05, 'epoch': 0.10038763542391413}\n",
            "{'loss': 0.6272, 'grad_norm': 4.80367374420166, 'learning_rate': 1.5945140131186644e-05, 'epoch': 0.10138157240830932}\n",
            "{'loss': 0.6622, 'grad_norm': 23.71907615661621, 'learning_rate': 1.5905386603061024e-05, 'epoch': 0.1023755093927045}\n",
            "{'loss': 0.5464, 'grad_norm': 5.280636787414551, 'learning_rate': 1.5865633074935402e-05, 'epoch': 0.10336944637709969}\n",
            "{'loss': 0.6571, 'grad_norm': 10.568273544311523, 'learning_rate': 1.5825879546809783e-05, 'epoch': 0.10436338336149488}\n",
            "{'loss': 0.801, 'grad_norm': 16.161596298217773, 'learning_rate': 1.578612601868416e-05, 'epoch': 0.10535732034589007}\n",
            "{'loss': 0.6654, 'grad_norm': 9.029358863830566, 'learning_rate': 1.574637249055854e-05, 'epoch': 0.10635125733028526}\n",
            "{'loss': 0.7413, 'grad_norm': 22.182750701904297, 'learning_rate': 1.5706618962432918e-05, 'epoch': 0.10734519431468045}\n",
            "{'loss': 0.594, 'grad_norm': 13.25252914428711, 'learning_rate': 1.5666865434307296e-05, 'epoch': 0.10833913129907564}\n",
            "{'loss': 0.5811, 'grad_norm': 18.569805145263672, 'learning_rate': 1.5627111906181676e-05, 'epoch': 0.10933306828347082}\n",
            "{'loss': 0.8362, 'grad_norm': 22.272401809692383, 'learning_rate': 1.5587358378056054e-05, 'epoch': 0.11032700526786601}\n",
            "{'loss': 0.7402, 'grad_norm': 26.707870483398438, 'learning_rate': 1.5547604849930434e-05, 'epoch': 0.1113209422522612}\n",
            "{'loss': 0.5123, 'grad_norm': 15.50747013092041, 'learning_rate': 1.5507851321804812e-05, 'epoch': 0.1123148792366564}\n",
            "{'loss': 0.6018, 'grad_norm': 25.031856536865234, 'learning_rate': 1.5468097793679193e-05, 'epoch': 0.11330881622105159}\n",
            "{'loss': 0.5463, 'grad_norm': 32.783363342285156, 'learning_rate': 1.542834426555357e-05, 'epoch': 0.11430275320544678}\n",
            "{'loss': 0.6806, 'grad_norm': 16.06018829345703, 'learning_rate': 1.5388590737427947e-05, 'epoch': 0.11529669018984197}\n",
            "{'loss': 0.5398, 'grad_norm': 14.92086410522461, 'learning_rate': 1.5348837209302328e-05, 'epoch': 0.11629062717423716}\n",
            "{'loss': 0.7262, 'grad_norm': 22.770586013793945, 'learning_rate': 1.5309083681176706e-05, 'epoch': 0.11728456415863234}\n",
            "{'loss': 0.7463, 'grad_norm': 19.934080123901367, 'learning_rate': 1.5269330153051086e-05, 'epoch': 0.11827850114302753}\n",
            "{'loss': 0.7138, 'grad_norm': 17.431974411010742, 'learning_rate': 1.5229576624925464e-05, 'epoch': 0.11927243812742272}\n",
            "{'loss': 0.6565, 'grad_norm': 8.595548629760742, 'learning_rate': 1.5189823096799843e-05, 'epoch': 0.12026637511181791}\n",
            "{'loss': 0.5743, 'grad_norm': 19.24818229675293, 'learning_rate': 1.5150069568674222e-05, 'epoch': 0.1212603120962131}\n",
            "{'loss': 0.6589, 'grad_norm': 17.829620361328125, 'learning_rate': 1.5110316040548601e-05, 'epoch': 0.1222542490806083}\n",
            "{'loss': 0.5282, 'grad_norm': 26.989818572998047, 'learning_rate': 1.507056251242298e-05, 'epoch': 0.12324818606500348}\n",
            "{'loss': 0.6497, 'grad_norm': 4.966513633728027, 'learning_rate': 1.5030808984297357e-05, 'epoch': 0.12424212304939866}\n",
            "{'loss': 0.5944, 'grad_norm': 10.151775360107422, 'learning_rate': 1.4991055456171736e-05, 'epoch': 0.12523606003379387}\n",
            "{'loss': 0.7112, 'grad_norm': 18.373857498168945, 'learning_rate': 1.4951301928046116e-05, 'epoch': 0.12622999701818904}\n",
            "{'loss': 0.5792, 'grad_norm': 16.109060287475586, 'learning_rate': 1.4911548399920495e-05, 'epoch': 0.12722393400258425}\n",
            "{'loss': 0.7224, 'grad_norm': 19.57439422607422, 'learning_rate': 1.4871794871794874e-05, 'epoch': 0.12821787098697943}\n",
            "{'loss': 0.6141, 'grad_norm': 28.631223678588867, 'learning_rate': 1.4832041343669253e-05, 'epoch': 0.1292118079713746}\n",
            "{'loss': 0.6281, 'grad_norm': 17.1739444732666, 'learning_rate': 1.4792287815543632e-05, 'epoch': 0.1302057449557698}\n",
            "{'loss': 0.6517, 'grad_norm': 15.042343139648438, 'learning_rate': 1.475253428741801e-05, 'epoch': 0.13119968194016499}\n",
            "{'loss': 0.749, 'grad_norm': 26.4462833404541, 'learning_rate': 1.4712780759292388e-05, 'epoch': 0.1321936189245602}\n",
            "{'loss': 0.5418, 'grad_norm': 16.269611358642578, 'learning_rate': 1.4673027231166767e-05, 'epoch': 0.13318755590895537}\n",
            "{'loss': 0.7725, 'grad_norm': 42.43207550048828, 'learning_rate': 1.4633273703041146e-05, 'epoch': 0.13418149289335057}\n",
            "{'loss': 0.6347, 'grad_norm': 16.03692626953125, 'learning_rate': 1.4593520174915526e-05, 'epoch': 0.13517542987774575}\n",
            "{'loss': 0.5839, 'grad_norm': 15.861345291137695, 'learning_rate': 1.4553766646789905e-05, 'epoch': 0.13616936686214093}\n",
            "{'loss': 0.6339, 'grad_norm': 12.567354202270508, 'learning_rate': 1.4514013118664284e-05, 'epoch': 0.13716330384653613}\n",
            "{'loss': 0.4782, 'grad_norm': 21.4009952545166, 'learning_rate': 1.4474259590538661e-05, 'epoch': 0.1381572408309313}\n",
            "{'loss': 0.7466, 'grad_norm': 8.24574089050293, 'learning_rate': 1.443450606241304e-05, 'epoch': 0.13915117781532652}\n",
            "{'loss': 0.6607, 'grad_norm': 38.01358413696289, 'learning_rate': 1.439475253428742e-05, 'epoch': 0.1401451147997217}\n",
            "{'loss': 0.5846, 'grad_norm': 9.472064971923828, 'learning_rate': 1.4354999006161798e-05, 'epoch': 0.1411390517841169}\n",
            "{'loss': 0.7131, 'grad_norm': 74.3136978149414, 'learning_rate': 1.4315245478036177e-05, 'epoch': 0.14213298876851208}\n",
            "{'loss': 0.5884, 'grad_norm': 61.02474594116211, 'learning_rate': 1.4275491949910556e-05, 'epoch': 0.14312692575290725}\n",
            "{'loss': 0.5431, 'grad_norm': 13.033156394958496, 'learning_rate': 1.4235738421784936e-05, 'epoch': 0.14412086273730246}\n",
            "{'loss': 0.4579, 'grad_norm': 16.376056671142578, 'learning_rate': 1.4195984893659313e-05, 'epoch': 0.14511479972169763}\n",
            "{'loss': 0.6857, 'grad_norm': 14.47128677368164, 'learning_rate': 1.4156231365533692e-05, 'epoch': 0.14610873670609284}\n",
            "{'loss': 0.6699, 'grad_norm': 17.618642807006836, 'learning_rate': 1.4116477837408071e-05, 'epoch': 0.14710267369048802}\n",
            "{'loss': 0.7578, 'grad_norm': 40.20433044433594, 'learning_rate': 1.407672430928245e-05, 'epoch': 0.14809661067488322}\n",
            "{'loss': 0.7023, 'grad_norm': 17.17085075378418, 'learning_rate': 1.403697078115683e-05, 'epoch': 0.1490905476592784}\n",
            "{'loss': 0.5054, 'grad_norm': 25.357446670532227, 'learning_rate': 1.3997217253031208e-05, 'epoch': 0.1500844846436736}\n",
            "{'loss': 0.5324, 'grad_norm': 26.049907684326172, 'learning_rate': 1.3957463724905587e-05, 'epoch': 0.15107842162806878}\n",
            "{'loss': 0.5559, 'grad_norm': 29.570228576660156, 'learning_rate': 1.3917710196779965e-05, 'epoch': 0.15207235861246396}\n",
            "{'loss': 0.8081, 'grad_norm': 29.364625930786133, 'learning_rate': 1.3877956668654344e-05, 'epoch': 0.15306629559685916}\n",
            "{'loss': 0.5798, 'grad_norm': 4.213842868804932, 'learning_rate': 1.3838203140528723e-05, 'epoch': 0.15406023258125434}\n",
            "{'loss': 0.5446, 'grad_norm': 31.9099063873291, 'learning_rate': 1.3798449612403102e-05, 'epoch': 0.15505416956564955}\n",
            "{'loss': 0.6315, 'grad_norm': 22.31570053100586, 'learning_rate': 1.3758696084277481e-05, 'epoch': 0.15604810655004472}\n",
            "{'loss': 0.7526, 'grad_norm': 28.124814987182617, 'learning_rate': 1.371894255615186e-05, 'epoch': 0.15704204353443993}\n",
            "{'loss': 0.4894, 'grad_norm': 8.438000679016113, 'learning_rate': 1.367918902802624e-05, 'epoch': 0.1580359805188351}\n",
            "{'loss': 0.5854, 'grad_norm': 21.267099380493164, 'learning_rate': 1.3639435499900617e-05, 'epoch': 0.15902991750323028}\n",
            "{'loss': 0.4569, 'grad_norm': 21.34504508972168, 'learning_rate': 1.3599681971774996e-05, 'epoch': 0.1600238544876255}\n",
            "{'loss': 0.7382, 'grad_norm': 6.903378963470459, 'learning_rate': 1.3559928443649375e-05, 'epoch': 0.16101779147202067}\n",
            "{'loss': 0.6624, 'grad_norm': 16.784957885742188, 'learning_rate': 1.3520174915523754e-05, 'epoch': 0.16201172845641587}\n",
            "{'loss': 0.6758, 'grad_norm': 34.28717041015625, 'learning_rate': 1.3480421387398133e-05, 'epoch': 0.16300566544081105}\n",
            "{'loss': 0.6287, 'grad_norm': 26.697002410888672, 'learning_rate': 1.3440667859272512e-05, 'epoch': 0.16399960242520625}\n",
            "{'loss': 0.5781, 'grad_norm': 53.90502166748047, 'learning_rate': 1.3400914331146891e-05, 'epoch': 0.16499353940960143}\n",
            "{'loss': 0.5647, 'grad_norm': 7.471855163574219, 'learning_rate': 1.3361160803021268e-05, 'epoch': 0.1659874763939966}\n",
            "{'loss': 0.6917, 'grad_norm': 28.015411376953125, 'learning_rate': 1.3321407274895648e-05, 'epoch': 0.1669814133783918}\n",
            "{'loss': 0.5393, 'grad_norm': 22.091890335083008, 'learning_rate': 1.3281653746770027e-05, 'epoch': 0.167975350362787}\n",
            "{'loss': 0.7559, 'grad_norm': 22.2752628326416, 'learning_rate': 1.3241900218644406e-05, 'epoch': 0.1689692873471822}\n",
            "{'loss': 0.6525, 'grad_norm': 11.6844482421875, 'learning_rate': 1.3202146690518785e-05, 'epoch': 0.16996322433157737}\n",
            "{'loss': 0.6493, 'grad_norm': 22.42707633972168, 'learning_rate': 1.3162393162393164e-05, 'epoch': 0.17095716131597258}\n",
            "{'loss': 0.6442, 'grad_norm': 45.210296630859375, 'learning_rate': 1.3122639634267543e-05, 'epoch': 0.17195109830036776}\n",
            "{'loss': 0.5855, 'grad_norm': 28.243783950805664, 'learning_rate': 1.308288610614192e-05, 'epoch': 0.17294503528476293}\n",
            "{'loss': 0.5362, 'grad_norm': 30.4898624420166, 'learning_rate': 1.30431325780163e-05, 'epoch': 0.17393897226915814}\n",
            "{'loss': 0.6867, 'grad_norm': 25.354480743408203, 'learning_rate': 1.3003379049890678e-05, 'epoch': 0.17493290925355331}\n",
            "{'loss': 0.689, 'grad_norm': 26.859216690063477, 'learning_rate': 1.2963625521765058e-05, 'epoch': 0.17592684623794852}\n",
            "{'loss': 0.6726, 'grad_norm': 34.3561897277832, 'learning_rate': 1.2923871993639437e-05, 'epoch': 0.1769207832223437}\n",
            "{'loss': 0.7351, 'grad_norm': 23.931827545166016, 'learning_rate': 1.2884118465513816e-05, 'epoch': 0.1779147202067389}\n",
            "{'loss': 0.674, 'grad_norm': 13.245491981506348, 'learning_rate': 1.2844364937388195e-05, 'epoch': 0.17890865719113408}\n",
            "{'loss': 0.5536, 'grad_norm': 13.789429664611816, 'learning_rate': 1.2804611409262572e-05, 'epoch': 0.17990259417552928}\n",
            "{'loss': 0.6939, 'grad_norm': 29.950349807739258, 'learning_rate': 1.2764857881136951e-05, 'epoch': 0.18089653115992446}\n",
            "{'loss': 0.5072, 'grad_norm': 9.950472831726074, 'learning_rate': 1.272510435301133e-05, 'epoch': 0.18189046814431964}\n",
            "{'loss': 0.7449, 'grad_norm': 23.8253231048584, 'learning_rate': 1.268535082488571e-05, 'epoch': 0.18288440512871484}\n",
            "{'loss': 0.6975, 'grad_norm': 18.670490264892578, 'learning_rate': 1.2645597296760088e-05, 'epoch': 0.18387834211311002}\n",
            "{'loss': 0.6154, 'grad_norm': 10.805562019348145, 'learning_rate': 1.2605843768634468e-05, 'epoch': 0.18487227909750523}\n",
            "{'loss': 0.5108, 'grad_norm': 30.368640899658203, 'learning_rate': 1.2566090240508847e-05, 'epoch': 0.1858662160819004}\n",
            "{'loss': 0.7309, 'grad_norm': 7.960031509399414, 'learning_rate': 1.2526336712383224e-05, 'epoch': 0.1868601530662956}\n",
            "{'loss': 0.5166, 'grad_norm': 15.842763900756836, 'learning_rate': 1.2486583184257603e-05, 'epoch': 0.1878540900506908}\n",
            "{'loss': 0.6763, 'grad_norm': 15.378445625305176, 'learning_rate': 1.2446829656131982e-05, 'epoch': 0.18884802703508596}\n",
            "{'loss': 0.6676, 'grad_norm': 15.73414421081543, 'learning_rate': 1.2407076128006361e-05, 'epoch': 0.18984196401948117}\n",
            "{'loss': 0.6613, 'grad_norm': 41.25432205200195, 'learning_rate': 1.236732259988074e-05, 'epoch': 0.19083590100387635}\n",
            "{'loss': 0.5817, 'grad_norm': 19.704296112060547, 'learning_rate': 1.232756907175512e-05, 'epoch': 0.19182983798827155}\n",
            "{'loss': 0.6593, 'grad_norm': 37.105220794677734, 'learning_rate': 1.2287815543629498e-05, 'epoch': 0.19282377497266673}\n",
            "{'loss': 0.5659, 'grad_norm': 14.05252456665039, 'learning_rate': 1.2248062015503876e-05, 'epoch': 0.19381771195706193}\n",
            "{'loss': 0.6328, 'grad_norm': 40.37371063232422, 'learning_rate': 1.2208308487378255e-05, 'epoch': 0.1948116489414571}\n",
            "{'loss': 0.7342, 'grad_norm': 21.447872161865234, 'learning_rate': 1.2168554959252634e-05, 'epoch': 0.1958055859258523}\n",
            "{'loss': 0.6094, 'grad_norm': 15.315467834472656, 'learning_rate': 1.2128801431127013e-05, 'epoch': 0.1967995229102475}\n",
            "{'loss': 0.5828, 'grad_norm': 56.17763900756836, 'learning_rate': 1.2089047903001392e-05, 'epoch': 0.19779345989464267}\n",
            "{'loss': 0.6265, 'grad_norm': 16.217525482177734, 'learning_rate': 1.2049294374875771e-05, 'epoch': 0.19878739687903788}\n",
            "{'loss': 0.6665, 'grad_norm': 25.84116554260254, 'learning_rate': 1.200954084675015e-05, 'epoch': 0.19978133386343305}\n",
            "{'loss': 0.5129, 'grad_norm': 26.635540008544922, 'learning_rate': 1.1969787318624528e-05, 'epoch': 0.20077527084782826}\n",
            "{'loss': 0.7008, 'grad_norm': 17.520492553710938, 'learning_rate': 1.1930033790498907e-05, 'epoch': 0.20176920783222344}\n",
            "{'loss': 0.5086, 'grad_norm': 27.524124145507812, 'learning_rate': 1.1890280262373286e-05, 'epoch': 0.20276314481661864}\n",
            "{'loss': 0.5537, 'grad_norm': 16.98008155822754, 'learning_rate': 1.1850526734247665e-05, 'epoch': 0.20375708180101382}\n",
            "{'loss': 0.5814, 'grad_norm': 31.797607421875, 'learning_rate': 1.1810773206122044e-05, 'epoch': 0.204751018785409}\n",
            "{'loss': 0.5673, 'grad_norm': 11.077277183532715, 'learning_rate': 1.1771019677996423e-05, 'epoch': 0.2057449557698042}\n",
            "{'loss': 0.5267, 'grad_norm': 24.984819412231445, 'learning_rate': 1.1731266149870802e-05, 'epoch': 0.20673889275419938}\n",
            "{'loss': 0.5748, 'grad_norm': 13.048660278320312, 'learning_rate': 1.169151262174518e-05, 'epoch': 0.20773282973859458}\n",
            "{'loss': 0.3759, 'grad_norm': 17.408287048339844, 'learning_rate': 1.1651759093619559e-05, 'epoch': 0.20872676672298976}\n",
            "{'loss': 0.3867, 'grad_norm': 35.64167404174805, 'learning_rate': 1.1612005565493938e-05, 'epoch': 0.20972070370738496}\n",
            "{'loss': 0.5608, 'grad_norm': 14.15285873413086, 'learning_rate': 1.1572252037368317e-05, 'epoch': 0.21071464069178014}\n",
            "{'loss': 0.8654, 'grad_norm': 35.91660690307617, 'learning_rate': 1.1532498509242696e-05, 'epoch': 0.21170857767617532}\n",
            "{'loss': 0.8489, 'grad_norm': 95.95573425292969, 'learning_rate': 1.1492744981117075e-05, 'epoch': 0.21270251466057052}\n",
            "{'loss': 0.7175, 'grad_norm': 13.928182601928711, 'learning_rate': 1.1452991452991454e-05, 'epoch': 0.2136964516449657}\n",
            "{'loss': 0.7116, 'grad_norm': 9.911253929138184, 'learning_rate': 1.1413237924865831e-05, 'epoch': 0.2146903886293609}\n",
            "{'loss': 0.6521, 'grad_norm': 19.95315933227539, 'learning_rate': 1.137348439674021e-05, 'epoch': 0.21568432561375608}\n",
            "{'loss': 0.621, 'grad_norm': 13.38116455078125, 'learning_rate': 1.133373086861459e-05, 'epoch': 0.2166782625981513}\n",
            "{'loss': 0.6739, 'grad_norm': 15.272930145263672, 'learning_rate': 1.1293977340488969e-05, 'epoch': 0.21767219958254647}\n",
            "{'loss': 0.5956, 'grad_norm': 22.705657958984375, 'learning_rate': 1.1254223812363348e-05, 'epoch': 0.21866613656694164}\n",
            "{'loss': 0.6156, 'grad_norm': 13.304038047790527, 'learning_rate': 1.1214470284237727e-05, 'epoch': 0.21966007355133685}\n",
            "{'loss': 0.6527, 'grad_norm': 14.50527572631836, 'learning_rate': 1.1174716756112106e-05, 'epoch': 0.22065401053573203}\n",
            "{'loss': 0.6065, 'grad_norm': 25.658109664916992, 'learning_rate': 1.1134963227986483e-05, 'epoch': 0.22164794752012723}\n",
            "{'loss': 0.7348, 'grad_norm': 11.227149963378906, 'learning_rate': 1.1095209699860862e-05, 'epoch': 0.2226418845045224}\n",
            "{'loss': 0.711, 'grad_norm': 15.461106300354004, 'learning_rate': 1.1055456171735241e-05, 'epoch': 0.2236358214889176}\n",
            "{'loss': 0.6075, 'grad_norm': 21.063718795776367, 'learning_rate': 1.101570264360962e-05, 'epoch': 0.2246297584733128}\n",
            "{'loss': 0.6548, 'grad_norm': 18.521738052368164, 'learning_rate': 1.0975949115484e-05, 'epoch': 0.22562369545770797}\n",
            "{'loss': 0.6017, 'grad_norm': 5.1416778564453125, 'learning_rate': 1.0936195587358379e-05, 'epoch': 0.22661763244210317}\n",
            "{'loss': 0.4758, 'grad_norm': 13.714158058166504, 'learning_rate': 1.0896442059232758e-05, 'epoch': 0.22761156942649835}\n",
            "{'loss': 0.6058, 'grad_norm': 79.72223663330078, 'learning_rate': 1.0856688531107135e-05, 'epoch': 0.22860550641089356}\n",
            "{'loss': 0.5943, 'grad_norm': 22.674728393554688, 'learning_rate': 1.0816935002981514e-05, 'epoch': 0.22959944339528873}\n",
            "{'loss': 0.6758, 'grad_norm': 17.36188316345215, 'learning_rate': 1.0777181474855893e-05, 'epoch': 0.23059338037968394}\n",
            "{'loss': 0.783, 'grad_norm': 35.038997650146484, 'learning_rate': 1.0737427946730272e-05, 'epoch': 0.23158731736407911}\n",
            "{'loss': 0.6935, 'grad_norm': 25.818355560302734, 'learning_rate': 1.0697674418604651e-05, 'epoch': 0.23258125434847432}\n",
            "{'loss': 0.6124, 'grad_norm': 12.286187171936035, 'learning_rate': 1.065792089047903e-05, 'epoch': 0.2335751913328695}\n",
            "{'loss': 0.4001, 'grad_norm': 15.902287483215332, 'learning_rate': 1.061816736235341e-05, 'epoch': 0.23456912831726467}\n",
            "{'loss': 0.604, 'grad_norm': 38.769718170166016, 'learning_rate': 1.0578413834227787e-05, 'epoch': 0.23556306530165988}\n",
            "{'loss': 0.5943, 'grad_norm': 12.638129234313965, 'learning_rate': 1.0538660306102166e-05, 'epoch': 0.23655700228605506}\n",
            "{'loss': 0.5893, 'grad_norm': 46.047672271728516, 'learning_rate': 1.0498906777976545e-05, 'epoch': 0.23755093927045026}\n",
            "{'loss': 0.6528, 'grad_norm': 12.864419937133789, 'learning_rate': 1.0459153249850924e-05, 'epoch': 0.23854487625484544}\n",
            "{'loss': 0.5924, 'grad_norm': 8.003795623779297, 'learning_rate': 1.0419399721725303e-05, 'epoch': 0.23953881323924064}\n",
            "{'loss': 0.8936, 'grad_norm': 18.69308090209961, 'learning_rate': 1.0379646193599682e-05, 'epoch': 0.24053275022363582}\n",
            "{'loss': 0.6392, 'grad_norm': 16.442096710205078, 'learning_rate': 1.0339892665474061e-05, 'epoch': 0.241526687208031}\n",
            "{'loss': 0.6661, 'grad_norm': 13.878401756286621, 'learning_rate': 1.0300139137348442e-05, 'epoch': 0.2425206241924262}\n",
            "{'loss': 0.5984, 'grad_norm': 12.275421142578125, 'learning_rate': 1.0260385609222821e-05, 'epoch': 0.24351456117682138}\n",
            "{'loss': 0.6324, 'grad_norm': 25.096590042114258, 'learning_rate': 1.0220632081097199e-05, 'epoch': 0.2445084981612166}\n",
            "{'loss': 0.5282, 'grad_norm': 18.44232177734375, 'learning_rate': 1.0180878552971578e-05, 'epoch': 0.24550243514561176}\n",
            "{'loss': 0.5406, 'grad_norm': 12.8291654586792, 'learning_rate': 1.0141125024845957e-05, 'epoch': 0.24649637213000697}\n",
            "{'loss': 0.558, 'grad_norm': 45.947731018066406, 'learning_rate': 1.0101371496720336e-05, 'epoch': 0.24749030911440215}\n",
            "{'loss': 0.6714, 'grad_norm': 44.975101470947266, 'learning_rate': 1.0061617968594715e-05, 'epoch': 0.24848424609879732}\n",
            "{'loss': 0.497, 'grad_norm': 20.569082260131836, 'learning_rate': 1.0021864440469094e-05, 'epoch': 0.24947818308319253}\n",
            "{'loss': 0.601, 'grad_norm': 31.97426414489746, 'learning_rate': 9.982110912343471e-06, 'epoch': 0.25047212006758773}\n",
            "{'loss': 0.5371, 'grad_norm': 19.402950286865234, 'learning_rate': 9.94235738421785e-06, 'epoch': 0.2514660570519829}\n",
            "{'loss': 0.6292, 'grad_norm': 31.246259689331055, 'learning_rate': 9.90260385609223e-06, 'epoch': 0.2524599940363781}\n",
            "{'loss': 0.7639, 'grad_norm': 55.9810905456543, 'learning_rate': 9.862850327966607e-06, 'epoch': 0.2534539310207733}\n",
            "{'loss': 0.6177, 'grad_norm': 31.107776641845703, 'learning_rate': 9.823096799840986e-06, 'epoch': 0.2544478680051685}\n",
            "{'loss': 0.5524, 'grad_norm': 23.22858238220215, 'learning_rate': 9.783343271715365e-06, 'epoch': 0.25544180498956365}\n",
            "{'loss': 0.5509, 'grad_norm': 18.95587921142578, 'learning_rate': 9.743589743589744e-06, 'epoch': 0.25643574197395885}\n",
            "{'loss': 0.7166, 'grad_norm': 15.668879508972168, 'learning_rate': 9.703836215464123e-06, 'epoch': 0.25742967895835406}\n",
            "{'loss': 0.6367, 'grad_norm': 11.336851119995117, 'learning_rate': 9.664082687338502e-06, 'epoch': 0.2584236159427492}\n",
            "{'loss': 0.6713, 'grad_norm': 16.15675926208496, 'learning_rate': 9.624329159212881e-06, 'epoch': 0.2594175529271444}\n",
            "{'loss': 0.5902, 'grad_norm': 33.02858352661133, 'learning_rate': 9.584575631087259e-06, 'epoch': 0.2604114899115396}\n",
            "{'loss': 0.5782, 'grad_norm': 12.4769926071167, 'learning_rate': 9.544822102961638e-06, 'epoch': 0.2614054268959348}\n",
            "{'loss': 0.5773, 'grad_norm': 10.031614303588867, 'learning_rate': 9.505068574836017e-06, 'epoch': 0.26239936388032997}\n",
            "{'loss': 0.6541, 'grad_norm': 16.48183250427246, 'learning_rate': 9.465315046710396e-06, 'epoch': 0.2633933008647252}\n",
            "{'loss': 0.6946, 'grad_norm': 22.87312889099121, 'learning_rate': 9.425561518584775e-06, 'epoch': 0.2643872378491204}\n",
            "{'loss': 0.7903, 'grad_norm': 29.486312866210938, 'learning_rate': 9.385807990459154e-06, 'epoch': 0.26538117483351553}\n",
            "{'loss': 0.605, 'grad_norm': 10.745612144470215, 'learning_rate': 9.346054462333533e-06, 'epoch': 0.26637511181791074}\n",
            "{'loss': 0.5983, 'grad_norm': 22.23569679260254, 'learning_rate': 9.30630093420791e-06, 'epoch': 0.26736904880230594}\n",
            "{'loss': 0.5759, 'grad_norm': 24.940771102905273, 'learning_rate': 9.26654740608229e-06, 'epoch': 0.26836298578670115}\n",
            "{'loss': 0.6488, 'grad_norm': 19.47054100036621, 'learning_rate': 9.226793877956669e-06, 'epoch': 0.2693569227710963}\n",
            "{'loss': 0.5477, 'grad_norm': 23.17888832092285, 'learning_rate': 9.187040349831048e-06, 'epoch': 0.2703508597554915}\n",
            "{'loss': 0.6005, 'grad_norm': 24.915159225463867, 'learning_rate': 9.147286821705427e-06, 'epoch': 0.2713447967398867}\n",
            "{'loss': 0.5106, 'grad_norm': 19.03803062438965, 'learning_rate': 9.107533293579806e-06, 'epoch': 0.27233873372428186}\n",
            "{'loss': 0.4734, 'grad_norm': 17.302265167236328, 'learning_rate': 9.067779765454185e-06, 'epoch': 0.27333267070867706}\n",
            "{'loss': 0.4025, 'grad_norm': 14.627206802368164, 'learning_rate': 9.028026237328562e-06, 'epoch': 0.27432660769307227}\n",
            "{'loss': 0.6093, 'grad_norm': 15.507770538330078, 'learning_rate': 8.988272709202941e-06, 'epoch': 0.27532054467746747}\n",
            "{'loss': 0.5723, 'grad_norm': 33.967735290527344, 'learning_rate': 8.94851918107732e-06, 'epoch': 0.2763144816618626}\n",
            "{'loss': 0.521, 'grad_norm': 21.617259979248047, 'learning_rate': 8.9087656529517e-06, 'epoch': 0.2773084186462578}\n",
            "{'loss': 0.5388, 'grad_norm': 16.247283935546875, 'learning_rate': 8.869012124826079e-06, 'epoch': 0.27830235563065303}\n",
            "{'loss': 0.5879, 'grad_norm': 43.5907096862793, 'learning_rate': 8.829258596700458e-06, 'epoch': 0.2792962926150482}\n",
            "{'loss': 0.5936, 'grad_norm': 14.356101036071777, 'learning_rate': 8.789505068574837e-06, 'epoch': 0.2802902295994434}\n",
            "{'loss': 0.6661, 'grad_norm': 10.120638847351074, 'learning_rate': 8.749751540449214e-06, 'epoch': 0.2812841665838386}\n",
            "{'loss': 0.5619, 'grad_norm': 26.28608512878418, 'learning_rate': 8.709998012323593e-06, 'epoch': 0.2822781035682338}\n",
            "{'loss': 0.5946, 'grad_norm': 10.81765365600586, 'learning_rate': 8.670244484197974e-06, 'epoch': 0.28327204055262895}\n",
            "{'loss': 0.4526, 'grad_norm': 30.22117042541504, 'learning_rate': 8.630490956072353e-06, 'epoch': 0.28426597753702415}\n",
            "{'loss': 0.5756, 'grad_norm': 13.388542175292969, 'learning_rate': 8.590737427946732e-06, 'epoch': 0.28525991452141936}\n",
            "{'loss': 0.598, 'grad_norm': 27.14992332458496, 'learning_rate': 8.55098389982111e-06, 'epoch': 0.2862538515058145}\n",
            "{'loss': 0.4239, 'grad_norm': 25.644535064697266, 'learning_rate': 8.511230371695489e-06, 'epoch': 0.2872477884902097}\n",
            "{'loss': 0.5768, 'grad_norm': 15.027560234069824, 'learning_rate': 8.471476843569868e-06, 'epoch': 0.2882417254746049}\n",
            "{'loss': 0.6269, 'grad_norm': 31.09998321533203, 'learning_rate': 8.431723315444247e-06, 'epoch': 0.2892356624590001}\n",
            "{'loss': 0.5643, 'grad_norm': 13.534222602844238, 'learning_rate': 8.391969787318626e-06, 'epoch': 0.29022959944339527}\n",
            "{'loss': 0.5258, 'grad_norm': 20.85324478149414, 'learning_rate': 8.352216259193005e-06, 'epoch': 0.2912235364277905}\n",
            "{'loss': 0.671, 'grad_norm': 21.091957092285156, 'learning_rate': 8.312462731067384e-06, 'epoch': 0.2922174734121857}\n",
            "{'loss': 0.4663, 'grad_norm': 23.344310760498047, 'learning_rate': 8.272709202941761e-06, 'epoch': 0.29321141039658083}\n",
            "{'loss': 0.5781, 'grad_norm': 19.3830509185791, 'learning_rate': 8.23295567481614e-06, 'epoch': 0.29420534738097603}\n",
            "{'loss': 0.7146, 'grad_norm': 25.746253967285156, 'learning_rate': 8.19320214669052e-06, 'epoch': 0.29519928436537124}\n",
            "{'loss': 0.5201, 'grad_norm': 26.058483123779297, 'learning_rate': 8.153448618564899e-06, 'epoch': 0.29619322134976644}\n",
            "{'loss': 0.5883, 'grad_norm': 26.95354461669922, 'learning_rate': 8.113695090439278e-06, 'epoch': 0.2971871583341616}\n",
            "{'loss': 0.7056, 'grad_norm': 53.90850067138672, 'learning_rate': 8.073941562313657e-06, 'epoch': 0.2981810953185568}\n",
            "{'loss': 0.8382, 'grad_norm': 26.652816772460938, 'learning_rate': 8.034188034188036e-06, 'epoch': 0.299175032302952}\n",
            "{'loss': 0.4767, 'grad_norm': 21.807964324951172, 'learning_rate': 7.994434506062413e-06, 'epoch': 0.3001689692873472}\n",
            "{'loss': 0.3665, 'grad_norm': 12.253636360168457, 'learning_rate': 7.954680977936792e-06, 'epoch': 0.30116290627174236}\n",
            "{'loss': 0.506, 'grad_norm': 16.952314376831055, 'learning_rate': 7.914927449811171e-06, 'epoch': 0.30215684325613756}\n",
            "{'loss': 0.6159, 'grad_norm': 28.543771743774414, 'learning_rate': 7.87517392168555e-06, 'epoch': 0.30315078024053277}\n",
            "{'loss': 0.539, 'grad_norm': 14.51354694366455, 'learning_rate': 7.83542039355993e-06, 'epoch': 0.3041447172249279}\n",
            "{'loss': 0.6865, 'grad_norm': 17.369972229003906, 'learning_rate': 7.795666865434309e-06, 'epoch': 0.3051386542093231}\n",
            "{'loss': 0.6195, 'grad_norm': 22.619890213012695, 'learning_rate': 7.755913337308688e-06, 'epoch': 0.30613259119371833}\n",
            "{'loss': 0.705, 'grad_norm': 10.861238479614258, 'learning_rate': 7.716159809183065e-06, 'epoch': 0.30712652817811353}\n",
            "{'loss': 0.529, 'grad_norm': 15.321932792663574, 'learning_rate': 7.676406281057444e-06, 'epoch': 0.3081204651625087}\n",
            "{'loss': 0.5716, 'grad_norm': 18.040782928466797, 'learning_rate': 7.636652752931823e-06, 'epoch': 0.3091144021469039}\n",
            "{'loss': 0.5605, 'grad_norm': 22.062341690063477, 'learning_rate': 7.596899224806202e-06, 'epoch': 0.3101083391312991}\n",
            "{'loss': 0.5024, 'grad_norm': 14.985207557678223, 'learning_rate': 7.5571456966805814e-06, 'epoch': 0.31110227611569424}\n",
            "{'loss': 0.712, 'grad_norm': 21.07192611694336, 'learning_rate': 7.51739216855496e-06, 'epoch': 0.31209621310008945}\n",
            "{'loss': 0.7639, 'grad_norm': 17.679656982421875, 'learning_rate': 7.477638640429339e-06, 'epoch': 0.31309015008448465}\n",
            "{'loss': 0.7503, 'grad_norm': 34.65263366699219, 'learning_rate': 7.437885112303718e-06, 'epoch': 0.31408408706887986}\n",
            "{'loss': 0.3856, 'grad_norm': 13.742396354675293, 'learning_rate': 7.398131584178097e-06, 'epoch': 0.315078024053275}\n",
            "{'loss': 0.4936, 'grad_norm': 12.747708320617676, 'learning_rate': 7.358378056052475e-06, 'epoch': 0.3160719610376702}\n",
            "{'loss': 0.5186, 'grad_norm': 15.106474876403809, 'learning_rate': 7.318624527926854e-06, 'epoch': 0.3170658980220654}\n",
            "{'loss': 0.6363, 'grad_norm': 35.72700119018555, 'learning_rate': 7.278870999801233e-06, 'epoch': 0.31805983500646057}\n",
            "{'loss': 0.692, 'grad_norm': 21.2465763092041, 'learning_rate': 7.2391174716756115e-06, 'epoch': 0.3190537719908558}\n",
            "{'loss': 0.681, 'grad_norm': 40.6751594543457, 'learning_rate': 7.199363943549991e-06, 'epoch': 0.320047708975251}\n",
            "{'loss': 0.4808, 'grad_norm': 46.02588653564453, 'learning_rate': 7.15961041542437e-06, 'epoch': 0.3210416459596462}\n",
            "{'loss': 0.6192, 'grad_norm': 13.50925064086914, 'learning_rate': 7.119856887298749e-06, 'epoch': 0.32203558294404133}\n",
            "{'loss': 0.5786, 'grad_norm': 29.09143829345703, 'learning_rate': 7.080103359173127e-06, 'epoch': 0.32302951992843654}\n",
            "{'loss': 0.5697, 'grad_norm': 30.434499740600586, 'learning_rate': 7.040349831047506e-06, 'epoch': 0.32402345691283174}\n",
            "{'loss': 0.5164, 'grad_norm': 9.443260192871094, 'learning_rate': 7.000596302921885e-06, 'epoch': 0.3250173938972269}\n",
            "{'loss': 0.6525, 'grad_norm': 10.810722351074219, 'learning_rate': 6.960842774796263e-06, 'epoch': 0.3260113308816221}\n",
            "{'loss': 0.5293, 'grad_norm': 24.604402542114258, 'learning_rate': 6.921089246670642e-06, 'epoch': 0.3270052678660173}\n",
            "{'loss': 0.4445, 'grad_norm': 27.997638702392578, 'learning_rate': 6.8813357185450215e-06, 'epoch': 0.3279992048504125}\n",
            "{'loss': 0.5347, 'grad_norm': 26.193946838378906, 'learning_rate': 6.8415821904194006e-06, 'epoch': 0.32899314183480766}\n",
            "{'loss': 0.674, 'grad_norm': 45.695316314697266, 'learning_rate': 6.801828662293779e-06, 'epoch': 0.32998707881920286}\n",
            "{'loss': 0.6433, 'grad_norm': 20.876544952392578, 'learning_rate': 6.762075134168158e-06, 'epoch': 0.33098101580359807}\n",
            "{'loss': 0.5123, 'grad_norm': 16.78000259399414, 'learning_rate': 6.722321606042537e-06, 'epoch': 0.3319749527879932}\n",
            "{'loss': 0.4901, 'grad_norm': 27.11968231201172, 'learning_rate': 6.682568077916915e-06, 'epoch': 0.3329688897723884}\n",
            "{'loss': 0.4524, 'grad_norm': 11.229705810546875, 'learning_rate': 6.642814549791294e-06, 'epoch': 0.3339628267567836}\n",
            "{'loss': 0.688, 'grad_norm': 12.521946907043457, 'learning_rate': 6.603061021665673e-06, 'epoch': 0.33495676374117883}\n",
            "{'loss': 0.4693, 'grad_norm': 22.792768478393555, 'learning_rate': 6.563307493540052e-06, 'epoch': 0.335950700725574}\n",
            "{'loss': 0.5606, 'grad_norm': 26.18427085876465, 'learning_rate': 6.523553965414431e-06, 'epoch': 0.3369446377099692}\n",
            "{'loss': 0.4595, 'grad_norm': 12.781197547912598, 'learning_rate': 6.48380043728881e-06, 'epoch': 0.3379385746943644}\n",
            "{'loss': 0.5032, 'grad_norm': 10.681679725646973, 'learning_rate': 6.444046909163189e-06, 'epoch': 0.33893251167875954}\n",
            "{'loss': 0.6758, 'grad_norm': 22.48174285888672, 'learning_rate': 6.404293381037567e-06, 'epoch': 0.33992644866315475}\n",
            "{'loss': 0.5035, 'grad_norm': 17.763765335083008, 'learning_rate': 6.364539852911946e-06, 'epoch': 0.34092038564754995}\n",
            "{'loss': 0.5255, 'grad_norm': 38.76952362060547, 'learning_rate': 6.324786324786325e-06, 'epoch': 0.34191432263194516}\n",
            "{'loss': 0.4586, 'grad_norm': 26.988412857055664, 'learning_rate': 6.285032796660704e-06, 'epoch': 0.3429082596163403}\n",
            "{'loss': 0.607, 'grad_norm': 33.207210540771484, 'learning_rate': 6.2452792685350825e-06, 'epoch': 0.3439021966007355}\n",
            "{'loss': 0.5243, 'grad_norm': 13.38592529296875, 'learning_rate': 6.2055257404094616e-06, 'epoch': 0.3448961335851307}\n",
            "{'loss': 0.559, 'grad_norm': 38.29301834106445, 'learning_rate': 6.165772212283841e-06, 'epoch': 0.34589007056952586}\n",
            "{'loss': 0.6351, 'grad_norm': 18.51346778869629, 'learning_rate': 6.126018684158219e-06, 'epoch': 0.34688400755392107}\n",
            "{'loss': 0.622, 'grad_norm': 13.816778182983398, 'learning_rate': 6.086265156032598e-06, 'epoch': 0.3478779445383163}\n",
            "{'loss': 0.4761, 'grad_norm': 16.943796157836914, 'learning_rate': 6.046511627906977e-06, 'epoch': 0.3488718815227115}\n",
            "{'loss': 0.6352, 'grad_norm': 21.67303466796875, 'learning_rate': 6.006758099781356e-06, 'epoch': 0.34986581850710663}\n",
            "{'loss': 0.6388, 'grad_norm': 13.482759475708008, 'learning_rate': 5.967004571655734e-06, 'epoch': 0.35085975549150183}\n",
            "{'loss': 0.5382, 'grad_norm': 23.089195251464844, 'learning_rate': 5.927251043530113e-06, 'epoch': 0.35185369247589704}\n",
            "{'loss': 0.5315, 'grad_norm': 28.07212257385254, 'learning_rate': 5.8874975154044925e-06, 'epoch': 0.35284762946029224}\n",
            "{'loss': 0.6648, 'grad_norm': 14.765316009521484, 'learning_rate': 5.847743987278871e-06, 'epoch': 0.3538415664446874}\n",
            "{'loss': 0.5965, 'grad_norm': 22.031352996826172, 'learning_rate': 5.80799045915325e-06, 'epoch': 0.3548355034290826}\n",
            "{'loss': 0.5829, 'grad_norm': 14.380389213562012, 'learning_rate': 5.768236931027629e-06, 'epoch': 0.3558294404134778}\n",
            "{'loss': 0.5323, 'grad_norm': 12.89477825164795, 'learning_rate': 5.728483402902008e-06, 'epoch': 0.35682337739787295}\n",
            "{'loss': 0.6652, 'grad_norm': 23.618988037109375, 'learning_rate': 5.688729874776386e-06, 'epoch': 0.35781731438226816}\n",
            "{'loss': 0.6943, 'grad_norm': 26.485395431518555, 'learning_rate': 5.648976346650765e-06, 'epoch': 0.35881125136666336}\n",
            "{'loss': 0.6068, 'grad_norm': 15.311631202697754, 'learning_rate': 5.609222818525144e-06, 'epoch': 0.35980518835105857}\n",
            "{'loss': 0.6677, 'grad_norm': 16.88770866394043, 'learning_rate': 5.5694692903995226e-06, 'epoch': 0.3607991253354537}\n",
            "{'loss': 0.576, 'grad_norm': 22.020442962646484, 'learning_rate': 5.529715762273902e-06, 'epoch': 0.3617930623198489}\n",
            "{'loss': 0.5892, 'grad_norm': 15.817294120788574, 'learning_rate': 5.489962234148281e-06, 'epoch': 0.36278699930424413}\n",
            "{'loss': 0.4921, 'grad_norm': 18.684816360473633, 'learning_rate': 5.450208706022661e-06, 'epoch': 0.3637809362886393}\n",
            "{'loss': 0.4407, 'grad_norm': 9.905287742614746, 'learning_rate': 5.41045517789704e-06, 'epoch': 0.3647748732730345}\n",
            "{'loss': 0.5138, 'grad_norm': 77.39090728759766, 'learning_rate': 5.370701649771418e-06, 'epoch': 0.3657688102574297}\n",
            "{'loss': 0.474, 'grad_norm': 11.009081840515137, 'learning_rate': 5.330948121645797e-06, 'epoch': 0.3667627472418249}\n",
            "{'loss': 0.6454, 'grad_norm': 3.9085934162139893, 'learning_rate': 5.291194593520176e-06, 'epoch': 0.36775668422622004}\n",
            "{'loss': 0.6323, 'grad_norm': 8.765979766845703, 'learning_rate': 5.251441065394554e-06, 'epoch': 0.36875062121061525}\n",
            "{'loss': 0.5852, 'grad_norm': 22.538738250732422, 'learning_rate': 5.211687537268933e-06, 'epoch': 0.36974455819501045}\n",
            "{'loss': 0.4482, 'grad_norm': 25.57392692565918, 'learning_rate': 5.1719340091433125e-06, 'epoch': 0.3707384951794056}\n",
            "{'loss': 0.4621, 'grad_norm': 51.81938171386719, 'learning_rate': 5.1321804810176915e-06, 'epoch': 0.3717324321638008}\n",
            "{'loss': 0.7657, 'grad_norm': 25.099647521972656, 'learning_rate': 5.09242695289207e-06, 'epoch': 0.372726369148196}\n",
            "{'loss': 0.6887, 'grad_norm': 9.001994132995605, 'learning_rate': 5.052673424766449e-06, 'epoch': 0.3737203061325912}\n",
            "{'loss': 0.4074, 'grad_norm': 11.009846687316895, 'learning_rate': 5.012919896640828e-06, 'epoch': 0.37471424311698637}\n",
            "{'loss': 0.7354, 'grad_norm': 14.414143562316895, 'learning_rate': 4.973166368515206e-06, 'epoch': 0.3757081801013816}\n",
            "{'loss': 0.5447, 'grad_norm': 36.85877227783203, 'learning_rate': 4.933412840389584e-06, 'epoch': 0.3767021170857768}\n",
            "{'loss': 0.6111, 'grad_norm': 19.810157775878906, 'learning_rate': 4.8936593122639635e-06, 'epoch': 0.3776960540701719}\n",
            "{'loss': 0.6661, 'grad_norm': 19.524494171142578, 'learning_rate': 4.8539057841383425e-06, 'epoch': 0.37868999105456713}\n",
            "{'loss': 0.4666, 'grad_norm': 15.857176780700684, 'learning_rate': 4.814152256012722e-06, 'epoch': 0.37968392803896234}\n",
            "{'loss': 0.5191, 'grad_norm': 27.42815589904785, 'learning_rate': 4.7743987278871e-06, 'epoch': 0.38067786502335754}\n",
            "{'loss': 0.5644, 'grad_norm': 13.1822509765625, 'learning_rate': 4.734645199761479e-06, 'epoch': 0.3816718020077527}\n",
            "{'loss': 0.6179, 'grad_norm': 27.418115615844727, 'learning_rate': 4.694891671635858e-06, 'epoch': 0.3826657389921479}\n",
            "{'loss': 0.5389, 'grad_norm': 12.429028511047363, 'learning_rate': 4.655138143510237e-06, 'epoch': 0.3836596759765431}\n",
            "{'loss': 0.5742, 'grad_norm': 23.51620864868164, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.38465361296093825}\n",
            "{'loss': 0.6719, 'grad_norm': 18.492027282714844, 'learning_rate': 4.575631087258995e-06, 'epoch': 0.38564754994533346}\n",
            "{'loss': 0.496, 'grad_norm': 36.41307067871094, 'learning_rate': 4.5358775591333735e-06, 'epoch': 0.38664148692972866}\n",
            "{'loss': 0.4967, 'grad_norm': 21.92264175415039, 'learning_rate': 4.4961240310077525e-06, 'epoch': 0.38763542391412387}\n",
            "{'loss': 0.6166, 'grad_norm': 27.235929489135742, 'learning_rate': 4.456370502882132e-06, 'epoch': 0.388629360898519}\n",
            "{'loss': 0.7094, 'grad_norm': 28.847618103027344, 'learning_rate': 4.41661697475651e-06, 'epoch': 0.3896232978829142}\n",
            "{'loss': 0.5707, 'grad_norm': 13.633081436157227, 'learning_rate': 4.376863446630889e-06, 'epoch': 0.3906172348673094}\n",
            "{'loss': 0.3948, 'grad_norm': 15.926854133605957, 'learning_rate': 4.337109918505268e-06, 'epoch': 0.3916111718517046}\n",
            "{'loss': 0.5358, 'grad_norm': 31.03170394897461, 'learning_rate': 4.297356390379647e-06, 'epoch': 0.3926051088360998}\n",
            "{'loss': 0.8234, 'grad_norm': 55.277889251708984, 'learning_rate': 4.257602862254025e-06, 'epoch': 0.393599045820495}\n",
            "{'loss': 0.5726, 'grad_norm': 9.57165241241455, 'learning_rate': 4.217849334128404e-06, 'epoch': 0.3945929828048902}\n",
            "{'loss': 0.4119, 'grad_norm': 16.345937728881836, 'learning_rate': 4.1780958060027835e-06, 'epoch': 0.39558691978928534}\n",
            "{'loss': 0.7139, 'grad_norm': 37.653629302978516, 'learning_rate': 4.138342277877162e-06, 'epoch': 0.39658085677368055}\n",
            "{'loss': 0.6763, 'grad_norm': 63.727725982666016, 'learning_rate': 4.098588749751541e-06, 'epoch': 0.39757479375807575}\n",
            "{'loss': 0.5727, 'grad_norm': 27.95281410217285, 'learning_rate': 4.05883522162592e-06, 'epoch': 0.3985687307424709}\n",
            "{'loss': 0.5365, 'grad_norm': 22.763212203979492, 'learning_rate': 4.019081693500299e-06, 'epoch': 0.3995626677268661}\n",
            "{'loss': 0.6854, 'grad_norm': 9.912696838378906, 'learning_rate': 3.979328165374677e-06, 'epoch': 0.4005566047112613}\n",
            "{'loss': 0.6598, 'grad_norm': 17.951444625854492, 'learning_rate': 3.939574637249056e-06, 'epoch': 0.4015505416956565}\n",
            "{'loss': 0.5193, 'grad_norm': 23.360870361328125, 'learning_rate': 3.899821109123435e-06, 'epoch': 0.40254447868005166}\n",
            "{'loss': 0.4733, 'grad_norm': 13.52578067779541, 'learning_rate': 3.8600675809978135e-06, 'epoch': 0.40353841566444687}\n",
            "{'loss': 0.5982, 'grad_norm': 25.371803283691406, 'learning_rate': 3.820314052872193e-06, 'epoch': 0.4045323526488421}\n",
            "{'loss': 0.5877, 'grad_norm': 25.496082305908203, 'learning_rate': 3.7805605247465717e-06, 'epoch': 0.4055262896332373}\n",
            "{'loss': 0.6186, 'grad_norm': 33.50156784057617, 'learning_rate': 3.7408069966209503e-06, 'epoch': 0.40652022661763243}\n",
            "{'loss': 0.6467, 'grad_norm': 28.90298843383789, 'learning_rate': 3.7010534684953294e-06, 'epoch': 0.40751416360202763}\n",
            "{'loss': 0.5515, 'grad_norm': 7.522799015045166, 'learning_rate': 3.661299940369708e-06, 'epoch': 0.40850810058642284}\n",
            "{'loss': 0.5115, 'grad_norm': 24.217729568481445, 'learning_rate': 3.6215464122440867e-06, 'epoch': 0.409502037570818}\n",
            "{'loss': 0.5239, 'grad_norm': 18.20685577392578, 'learning_rate': 3.581792884118466e-06, 'epoch': 0.4104959745552132}\n",
            "{'loss': 0.6143, 'grad_norm': 22.68229866027832, 'learning_rate': 3.5420393559928444e-06, 'epoch': 0.4114899115396084}\n",
            "{'loss': 0.5435, 'grad_norm': 19.230976104736328, 'learning_rate': 3.5022858278672235e-06, 'epoch': 0.4124838485240036}\n",
            "{'loss': 0.5097, 'grad_norm': 20.585786819458008, 'learning_rate': 3.462532299741602e-06, 'epoch': 0.41347778550839875}\n",
            "{'loss': 0.4095, 'grad_norm': 18.197507858276367, 'learning_rate': 3.4227787716159812e-06, 'epoch': 0.41447172249279396}\n",
            "{'loss': 0.4974, 'grad_norm': 18.97519302368164, 'learning_rate': 3.38302524349036e-06, 'epoch': 0.41546565947718916}\n",
            "{'loss': 0.7893, 'grad_norm': 36.22021484375, 'learning_rate': 3.3432717153647386e-06, 'epoch': 0.4164595964615843}\n",
            "{'loss': 0.4355, 'grad_norm': 10.67585277557373, 'learning_rate': 3.3035181872391176e-06, 'epoch': 0.4174535334459795}\n",
            "{'loss': 0.5589, 'grad_norm': 19.067035675048828, 'learning_rate': 3.2637646591134963e-06, 'epoch': 0.4184474704303747}\n",
            "{'loss': 0.6811, 'grad_norm': 44.806251525878906, 'learning_rate': 3.2240111309878754e-06, 'epoch': 0.41944140741476993}\n",
            "{'loss': 0.5925, 'grad_norm': 9.240518569946289, 'learning_rate': 3.184257602862254e-06, 'epoch': 0.4204353443991651}\n",
            "{'loss': 0.5891, 'grad_norm': 6.155583381652832, 'learning_rate': 3.144504074736633e-06, 'epoch': 0.4214292813835603}\n",
            "{'loss': 0.7159, 'grad_norm': 20.900121688842773, 'learning_rate': 3.1047505466110117e-06, 'epoch': 0.4224232183679555}\n",
            "{'loss': 0.6701, 'grad_norm': 28.30733871459961, 'learning_rate': 3.0649970184853904e-06, 'epoch': 0.42341715535235064}\n",
            "{'loss': 0.5806, 'grad_norm': 43.576778411865234, 'learning_rate': 3.02524349035977e-06, 'epoch': 0.42441109233674584}\n",
            "{'loss': 0.6483, 'grad_norm': 16.36810302734375, 'learning_rate': 2.985489962234149e-06, 'epoch': 0.42540502932114105}\n",
            "{'loss': 0.3014, 'grad_norm': 18.88675308227539, 'learning_rate': 2.9457364341085276e-06, 'epoch': 0.42639896630553625}\n",
            "{'loss': 0.7732, 'grad_norm': 14.863971710205078, 'learning_rate': 2.9059829059829063e-06, 'epoch': 0.4273929032899314}\n",
            "{'loss': 0.4736, 'grad_norm': 26.538917541503906, 'learning_rate': 2.8662293778572854e-06, 'epoch': 0.4283868402743266}\n",
            "{'loss': 0.5493, 'grad_norm': 17.85393524169922, 'learning_rate': 2.826475849731664e-06, 'epoch': 0.4293807772587218}\n",
            "{'loss': 0.6805, 'grad_norm': 19.260068893432617, 'learning_rate': 2.786722321606043e-06, 'epoch': 0.43037471424311696}\n",
            "{'loss': 0.7641, 'grad_norm': 17.574190139770508, 'learning_rate': 2.7469687934804217e-06, 'epoch': 0.43136865122751217}\n",
            "{'loss': 0.7136, 'grad_norm': 20.40403938293457, 'learning_rate': 2.707215265354801e-06, 'epoch': 0.4323625882119074}\n",
            "{'loss': 0.5997, 'grad_norm': 22.566686630249023, 'learning_rate': 2.6674617372291795e-06, 'epoch': 0.4333565251963026}\n",
            "{'loss': 0.8138, 'grad_norm': 32.564971923828125, 'learning_rate': 2.627708209103558e-06, 'epoch': 0.4343504621806977}\n",
            "{'loss': 0.5597, 'grad_norm': 20.777963638305664, 'learning_rate': 2.587954680977937e-06, 'epoch': 0.43534439916509293}\n",
            "{'loss': 0.5121, 'grad_norm': 26.194316864013672, 'learning_rate': 2.548201152852316e-06, 'epoch': 0.43633833614948814}\n",
            "{'loss': 0.719, 'grad_norm': 15.12753677368164, 'learning_rate': 2.508447624726695e-06, 'epoch': 0.4373322731338833}\n",
            "{'loss': 0.7309, 'grad_norm': 22.787826538085938, 'learning_rate': 2.4686940966010736e-06, 'epoch': 0.4383262101182785}\n",
            "{'loss': 0.6903, 'grad_norm': 70.52198028564453, 'learning_rate': 2.4289405684754527e-06, 'epoch': 0.4393201471026737}\n",
            "{'loss': 0.4921, 'grad_norm': 19.16168212890625, 'learning_rate': 2.3891870403498313e-06, 'epoch': 0.4403140840870689}\n",
            "{'loss': 0.6041, 'grad_norm': 25.801788330078125, 'learning_rate': 2.34943351222421e-06, 'epoch': 0.44130802107146405}\n",
            "{'loss': 0.4946, 'grad_norm': 19.928075790405273, 'learning_rate': 2.309679984098589e-06, 'epoch': 0.44230195805585926}\n",
            "{'loss': 0.5271, 'grad_norm': 19.28445053100586, 'learning_rate': 2.2699264559729677e-06, 'epoch': 0.44329589504025446}\n",
            "{'loss': 0.4886, 'grad_norm': 33.05508804321289, 'learning_rate': 2.2301729278473468e-06, 'epoch': 0.4442898320246496}\n",
            "{'loss': 0.4678, 'grad_norm': 63.0572509765625, 'learning_rate': 2.1904193997217254e-06, 'epoch': 0.4452837690090448}\n",
            "{'loss': 0.6981, 'grad_norm': 21.3218994140625, 'learning_rate': 2.1506658715961045e-06, 'epoch': 0.44627770599344}\n",
            "{'loss': 0.6567, 'grad_norm': 27.921079635620117, 'learning_rate': 2.110912343470483e-06, 'epoch': 0.4472716429778352}\n",
            "{'loss': 0.6712, 'grad_norm': 35.04319381713867, 'learning_rate': 2.071158815344862e-06, 'epoch': 0.4482655799622304}\n",
            "{'loss': 0.5341, 'grad_norm': 4.927706241607666, 'learning_rate': 2.031405287219241e-06, 'epoch': 0.4492595169466256}\n",
            "{'loss': 0.6539, 'grad_norm': 20.40089988708496, 'learning_rate': 1.9916517590936195e-06, 'epoch': 0.4502534539310208}\n",
            "{'loss': 0.5743, 'grad_norm': 28.25395965576172, 'learning_rate': 1.9518982309679986e-06, 'epoch': 0.45124739091541594}\n",
            "{'loss': 0.6295, 'grad_norm': 28.811922073364258, 'learning_rate': 1.9121447028423773e-06, 'epoch': 0.45224132789981114}\n",
            "{'loss': 0.5855, 'grad_norm': 13.014392852783203, 'learning_rate': 1.8723911747167561e-06, 'epoch': 0.45323526488420635}\n",
            "{'loss': 0.6433, 'grad_norm': 26.08338165283203, 'learning_rate': 1.8326376465911352e-06, 'epoch': 0.45422920186860155}\n",
            "{'loss': 0.5762, 'grad_norm': 15.488659858703613, 'learning_rate': 1.792884118465514e-06, 'epoch': 0.4552231388529967}\n",
            "{'loss': 0.5742, 'grad_norm': 16.871538162231445, 'learning_rate': 1.753130590339893e-06, 'epoch': 0.4562170758373919}\n",
            "{'loss': 0.5192, 'grad_norm': 26.785654067993164, 'learning_rate': 1.7133770622142718e-06, 'epoch': 0.4572110128217871}\n",
            "{'loss': 0.7232, 'grad_norm': 31.64252281188965, 'learning_rate': 1.6736235340886507e-06, 'epoch': 0.4582049498061823}\n",
            "{'loss': 0.5597, 'grad_norm': 16.13924789428711, 'learning_rate': 1.6338700059630293e-06, 'epoch': 0.45919888679057747}\n",
            "{'loss': 0.606, 'grad_norm': 14.247642517089844, 'learning_rate': 1.5941164778374082e-06, 'epoch': 0.46019282377497267}\n",
            "{'loss': 0.6455, 'grad_norm': 26.689266204833984, 'learning_rate': 1.554362949711787e-06, 'epoch': 0.4611867607593679}\n",
            "{'loss': 0.5258, 'grad_norm': 12.667793273925781, 'learning_rate': 1.514609421586166e-06, 'epoch': 0.462180697743763}\n",
            "{'loss': 0.7, 'grad_norm': 30.154006958007812, 'learning_rate': 1.4748558934605448e-06, 'epoch': 0.46317463472815823}\n",
            "{'loss': 0.4743, 'grad_norm': 2.8585660457611084, 'learning_rate': 1.4351023653349236e-06, 'epoch': 0.46416857171255343}\n",
            "{'loss': 0.6723, 'grad_norm': 7.500487804412842, 'learning_rate': 1.3953488372093025e-06, 'epoch': 0.46516250869694864}\n",
            "{'loss': 0.7537, 'grad_norm': 40.56073760986328, 'learning_rate': 1.3555953090836812e-06, 'epoch': 0.4661564456813438}\n",
            "{'loss': 0.5538, 'grad_norm': 13.838680267333984, 'learning_rate': 1.31584178095806e-06, 'epoch': 0.467150382665739}\n",
            "{'loss': 0.7505, 'grad_norm': 32.354576110839844, 'learning_rate': 1.2760882528324389e-06, 'epoch': 0.4681443196501342}\n",
            "{'loss': 0.5208, 'grad_norm': 28.816808700561523, 'learning_rate': 1.236334724706818e-06, 'epoch': 0.46913825663452935}\n",
            "{'loss': 0.5083, 'grad_norm': 14.697367668151855, 'learning_rate': 1.1965811965811968e-06, 'epoch': 0.47013219361892455}\n",
            "{'loss': 0.6413, 'grad_norm': 19.279930114746094, 'learning_rate': 1.1568276684555755e-06, 'epoch': 0.47112613060331976}\n",
            "{'loss': 0.5935, 'grad_norm': 23.3574161529541, 'learning_rate': 1.1170741403299543e-06, 'epoch': 0.47212006758771496}\n",
            "{'loss': 0.6337, 'grad_norm': 17.828432083129883, 'learning_rate': 1.0773206122043332e-06, 'epoch': 0.4731140045721101}\n",
            "{'loss': 0.5783, 'grad_norm': 13.341554641723633, 'learning_rate': 1.037567084078712e-06, 'epoch': 0.4741079415565053}\n",
            "{'loss': 0.6083, 'grad_norm': 15.822556495666504, 'learning_rate': 9.97813555953091e-07, 'epoch': 0.4751018785409005}\n",
            "{'loss': 0.5222, 'grad_norm': 18.499408721923828, 'learning_rate': 9.580600278274698e-07, 'epoch': 0.4760958155252957}\n",
            "{'loss': 0.5243, 'grad_norm': 19.598215103149414, 'learning_rate': 9.183064997018486e-07, 'epoch': 0.4770897525096909}\n",
            "{'loss': 0.6124, 'grad_norm': 30.417247772216797, 'learning_rate': 8.785529715762274e-07, 'epoch': 0.4780836894940861}\n",
            "{'loss': 0.6038, 'grad_norm': 13.598566055297852, 'learning_rate': 8.387994434506064e-07, 'epoch': 0.4790776264784813}\n",
            "{'loss': 0.5612, 'grad_norm': 24.800586700439453, 'learning_rate': 7.990459153249853e-07, 'epoch': 0.48007156346287644}\n",
            "{'loss': 0.4508, 'grad_norm': 18.660213470458984, 'learning_rate': 7.59292387199364e-07, 'epoch': 0.48106550044727164}\n",
            "{'loss': 0.6207, 'grad_norm': 25.99741554260254, 'learning_rate': 7.195388590737429e-07, 'epoch': 0.48205943743166685}\n",
            "{'loss': 0.4746, 'grad_norm': 22.280385971069336, 'learning_rate': 6.797853309481218e-07, 'epoch': 0.483053374416062}\n",
            "{'loss': 0.5202, 'grad_norm': 27.19939422607422, 'learning_rate': 6.400318028225005e-07, 'epoch': 0.4840473114004572}\n",
            "{'loss': 0.3606, 'grad_norm': 12.205883026123047, 'learning_rate': 6.002782746968794e-07, 'epoch': 0.4850412483848524}\n",
            "{'loss': 0.5928, 'grad_norm': 33.20569610595703, 'learning_rate': 5.605247465712582e-07, 'epoch': 0.4860351853692476}\n",
            "{'loss': 0.5068, 'grad_norm': 22.28791618347168, 'learning_rate': 5.207712184456371e-07, 'epoch': 0.48702912235364276}\n",
            "{'loss': 0.5648, 'grad_norm': 28.814720153808594, 'learning_rate': 4.81017690320016e-07, 'epoch': 0.48802305933803797}\n",
            "{'loss': 0.478, 'grad_norm': 7.254702568054199, 'learning_rate': 4.412641621943948e-07, 'epoch': 0.4890169963224332}\n",
            "{'loss': 0.6488, 'grad_norm': 16.14097023010254, 'learning_rate': 4.0151063406877365e-07, 'epoch': 0.4900109333068283}\n",
            "{'loss': 0.4806, 'grad_norm': 26.848276138305664, 'learning_rate': 3.6175710594315246e-07, 'epoch': 0.4910048702912235}\n",
            "{'loss': 0.5288, 'grad_norm': 15.522727966308594, 'learning_rate': 3.220035778175314e-07, 'epoch': 0.49199880727561873}\n",
            "{'loss': 0.5474, 'grad_norm': 67.96063232421875, 'learning_rate': 2.822500496919102e-07, 'epoch': 0.49299274426001394}\n",
            "{'loss': 0.4946, 'grad_norm': 15.475946426391602, 'learning_rate': 2.4249652156628905e-07, 'epoch': 0.4939866812444091}\n",
            "{'loss': 0.4972, 'grad_norm': 22.431880950927734, 'learning_rate': 2.0274299344066786e-07, 'epoch': 0.4949806182288043}\n",
            "{'loss': 0.5879, 'grad_norm': 24.795366287231445, 'learning_rate': 1.6298946531504673e-07, 'epoch': 0.4959745552131995}\n",
            "{'loss': 0.522, 'grad_norm': 4.441494464874268, 'learning_rate': 1.2323593718942557e-07, 'epoch': 0.49696849219759465}\n",
            "{'loss': 0.5729, 'grad_norm': 10.964775085449219, 'learning_rate': 8.348240906380442e-08, 'epoch': 0.49796242918198985}\n",
            "{'loss': 0.4711, 'grad_norm': 28.083332061767578, 'learning_rate': 4.372888093818327e-08, 'epoch': 0.49895636616638506}\n",
            "{'loss': 0.5037, 'grad_norm': 25.41733741760254, 'learning_rate': 3.975352812562115e-09, 'epoch': 0.49995030315078026}\n",
            "{'eval_loss': 0.6540827751159668, 'eval_runtime': 22.6474, 'eval_samples_per_second': 158.958, 'eval_steps_per_second': 19.87, 'epoch': 0.5000496968492197}\n",
            "{'train_runtime': 897.2755, 'train_samples_per_second': 44.851, 'train_steps_per_second': 5.607, 'train_loss': 0.630693681764688, 'epoch': 0.5000496968492197}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5031, training_loss=0.630693681764688, metrics={'train_runtime': 897.2755, 'train_samples_per_second': 44.851, 'train_steps_per_second': 5.607, 'train_loss': 0.630693681764688, 'epoch': 0.5000496968492197})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "\n",
        "# 1) Text description of my sytem\n",
        "# This system leverages the pretrained RoBERTa model instead of BERT model.\n",
        "# RoBERTa refines BERT by training on more extensive data with dynamic masking\n",
        "# and without the Next Sentence Prediction objective. This approach enhances\n",
        "# its performance on various NLP tasks, including sentiment analysis.\n",
        "# Therefore, I tried to use RoBERTa instaed of BERT\n",
        "\n",
        "# 2) The code for my system\n",
        "# I re-wrote training part to allow more flexible training parameter control\n",
        "# Based on the pre-trained RoBERTa model, I have fine-tuned classifier for sentiment analysis.\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DefaultDataCollator\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Initialize the tokenizer for RoBERTa\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def get_batch_token_ids(batch, tokenizer):\n",
        "    \"\"\"Map `batch` to a tensor of ids. The return\n",
        "    value should meet the following specification:\n",
        "    1. The max length should be 512.\n",
        "    2. Examples longer than the max length should be truncated\n",
        "    3. Examples should be padded to the max length for the batch.\n",
        "    4. The special [CLS] should be added to the start and the special\n",
        "       token [SEP] should be added to the end.\n",
        "    5. The attention mask should be returned\n",
        "    6. The return value of each component should be a tensor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch: list of str\n",
        "    tokenizer: Hugging Face tokenizer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict with at least \"input_ids\" and \"attention_mask\" as keys,\n",
        "    each with Tensor values\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "    result = tokenizer.batch_encode_plus(\n",
        "        batch,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt')\n",
        "\n",
        "    return result\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n",
        "\n",
        "def build_dataset(tokenizer, X, y=None):\n",
        "    data = get_batch_token_ids(X, tokenizer)\n",
        "\n",
        "    # Create a list of dictionaries instead of using TensorDataset\n",
        "    features = []\n",
        "    for i in range(len(data['input_ids'])):\n",
        "        feature = {\n",
        "            'input_ids': data['input_ids'][i],\n",
        "            'attention_mask': data['attention_mask'][i]\n",
        "        }\n",
        "        if y is not None:\n",
        "            classes_ = sorted(set(y))\n",
        "            n_classes_ = len(classes_)\n",
        "            class2index = dict(zip(classes_, range(n_classes_)))\n",
        "            feature['labels'] = class2index[y[i]]  # Use 'labels' key\n",
        "        features.append(feature)\n",
        "\n",
        "    return features  # Return the list of features\n",
        "\n",
        "small_train_dataset = build_dataset(tokenizer,\n",
        "    dynasent_r1['train']['sentence'],\n",
        "    dynasent_r1['train']['gold_label'])\n",
        "\n",
        "small_eval_dataset = build_dataset(tokenizer,\n",
        "   dynasent_r1['validation']['sentence'],\n",
        "    dynasent_r1['validation']['gold_label'])\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=0.5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    disable_tqdm=True,  # Enable progress bar\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Use DefaultDataCollator with tokenizer\n",
        "data_collator = DefaultDataCollator()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "### Make predictions in the validation set and create classification table\n",
        "import numpy as np\n",
        "\n",
        "predictions_RoBERTa = trainer.predict(small_eval_dataset)\n",
        "preds_RoBERTa = np.argmax(predictions_RoBERTa.predictions, axis=-1)\n",
        "\n",
        "# Convert preds_RoBERTa to string labels to match dynasent_r1 labels\n",
        "# Assuming your labels are in the order: [negative=0, positive=1, neutral=2]\n",
        "label_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
        "preds_RoBERTa_str = [label_mapping[pred] for pred in preds_RoBERTa]\n",
        "\n",
        "print(classification_report(dynasent_r1['validation']['gold_label'], preds_RoBERTa_str, digits=3))\n",
        "\n",
        "\n",
        "# STOP COMMENT: Please do not remove this comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_B1ZmZCBg_m"
      },
      "source": [
        "## Question 4: Bakeoff entry [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpBwDzBzBg_n"
      },
      "source": [
        "The bakeoff dataset is available at\n",
        "\n",
        "https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv\n",
        "\n",
        "This code should grab it for you and put it in `data/sentiment` if you are working in the cloud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hZr2vErNBg_n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "if not os.path.exists(os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\")):\n",
        "    os.makedirs(os.path.join('data', 'sentiment'), exist_ok=True)\n",
        "    wget.download('https://web.stanford.edu/class/cs224u/data/cs224u-sentiment-test-unlabeled.csv', out='data/sentiment/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9PKtOFeBg_n"
      },
      "source": [
        "If the above fails, you can just download the file and place it in `data/sentiment`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg6FoIK0Bg_n"
      },
      "source": [
        "Once you have the file, you can load it to a `pd.DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_rQ-Ypz0Bg_n"
      },
      "outputs": [],
      "source": [
        "bakeoff_df = pd.read_csv(\n",
        "    os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hr1w8joKBg_n",
        "outputId": "eef4994a-775b-4de8-c70e-fbaac7826bce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   example_id                                           sentence\n",
              "0           0  This year we were at a restaurant that clearly...\n",
              "1           1                                        A long way.\n",
              "2           2  A friend and I went on a Thursday evening  aro...\n",
              "3           3  You'll love to say I used to be married to tha...\n",
              "4           4  I feel like any place I move will be a downgra..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35624fb7-6d24-4cb2-bec5-0da5887229e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>This year we were at a restaurant that clearly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A long way.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A friend and I went on a Thursday evening  aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You'll love to say I used to be married to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I feel like any place I move will be a downgra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35624fb7-6d24-4cb2-bec5-0da5887229e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35624fb7-6d24-4cb2-bec5-0da5887229e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35624fb7-6d24-4cb2-bec5-0da5887229e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7241062f-cb15-4aac-9137-607c2b83942b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7241062f-cb15-4aac-9137-607c2b83942b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7241062f-cb15-4aac-9137-607c2b83942b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bakeoff_df",
              "summary": "{\n  \"name\": \"bakeoff_df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"example_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 866,\n        \"min\": 0,\n        \"max\": 2999,\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          1801,\n          1190,\n          1817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3000,\n        \"samples\": [\n          \"One down fall was the $385 bill for two.\",\n          \"We had lunch. The waiter mis-ordered two out of three meals. the food was good, not great.\",\n          \"a movie that will touch the hearts of both children and adults , as well as bring audiences to the edge of their seats .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "bakeoff_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5puzxxqPBg_n"
      },
      "source": [
        "To enter the bakeoff, you simply need to use your original system to:\n",
        "\n",
        "1. Add a column named 'prediction' to `cs224u-sentiment-test-unlabeled.csv` with your model predictions (which are strings in {`positive`, `negative`, `neutral`}). The existing columns should remain.\n",
        "\n",
        "2. Save the file as `cs224u-sentiment-bakeoff-entry.csv`. Here is a good snippet of code for writing this file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8O0UlyPBg_o",
        "outputId": "53c2c5b4-4331-49a9-da47-7306dd1d624f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This is a placeholder for adding the \"prediction\" column:\n",
        "inputs = build_dataset(tokenizer,\n",
        "    bakeoff_df['sentence'].tolist())\n",
        "\n",
        "predictions_test = trainer.predict(inputs)\n",
        "preds_test = np.argmax(predictions_test.predictions, axis=-1)\n",
        "\n",
        "# Convert preds_RoBERTa to string labels to match dynasent_r1 labels\n",
        "# Assuming your labels are in the order: [negative=0, positive=1, neutral=2]\n",
        "label_mapping = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
        "preds_test_str = [label_mapping[pred] for pred in preds_test]\n",
        "\n",
        "bakeoff_df['prediction'] = preds_test_str # Use your model to add predictions.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Write to disk\n",
        "bakeoff_df.to_csv(\"cs224u-sentiment-bakeoff-entry.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtjHzJP72qjZ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCclbToWBg_o"
      },
      "source": [
        "In particular, you need to be sure that `example_id` is a column rather than an index when read in by Pandas. Here is a quick test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "vMJcdnvYBg_o"
      },
      "outputs": [],
      "source": [
        "def test_bakeoff_entry(filename=\"cs224u-sentiment-bakeoff-entry.csv\"):\n",
        "    gold_df = pd.read_csv(\n",
        "        os.path.join(\"data\", \"sentiment\", \"cs224u-sentiment-test-unlabeled.csv\"))\n",
        "    entry_df = pd.read_csv(filename)\n",
        "\n",
        "    # Check that no required columns are missing:\n",
        "    expected_cols = {'example_id', 'sentence', 'prediction'}\n",
        "    missing_cols = expected_cols - set(entry_df.columns)\n",
        "    errcount = 0\n",
        "    if len(missing_cols) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Entry is missing required columns {missing_cols}\")\n",
        "        return\n",
        "\n",
        "    # Check that the predictions are in our space:\n",
        "    labels = {'positive', 'negative', 'neutral'}\n",
        "    predtypes = set(entry_df.prediction.unique())\n",
        "    unexpected = predtypes - labels\n",
        "    if len(unexpected) != 0:\n",
        "        errcount += 1\n",
        "        print(f\"Prediction column has unexpected values: {unexpected}\")\n",
        "\n",
        "    # Check that the dataset hasn't been rearranged:\n",
        "    for colname in ('example_id', 'sentence'):\n",
        "        if not entry_df[colname].equals(gold_df[colname]):\n",
        "            errcount += 1\n",
        "            print(f\"Entry is misaligned with test data on column {colname}\")\n",
        "\n",
        "    # Clean bill of health:\n",
        "    if errcount == 0:\n",
        "        print(\"No errors detected with `test_bakeoff_entry`.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I72u1fhyBg_o",
        "outputId": "1e6beb68-0898-470a-d0fd-2b852134a4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors detected with `test_bakeoff_entry`.\n"
          ]
        }
      ],
      "source": [
        "test_bakeoff_entry(\"cs224u-sentiment-bakeoff-entry.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGaEfAYtBg_o"
      },
      "source": [
        "Submit the following files to Gradescope:\n",
        "\n",
        "* `hw_sentiment.ipynb` (this notebook)\n",
        "* `cs224u-sentiment-bakeoff-entry.csv` (bake-off output)\n",
        "\n",
        "Please make sure you use these filenames. The autograder looks for files with these names.\n",
        "\n",
        "You are not permitted to do any tuning of your system based on what you see in our bakeoff prediction file – you should not study that file in anyway, beyond perhaps checking that it contains what you expected it to contain. The upload function will do some additional checking to ensure that your file is well-formed.\n",
        "\n",
        "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
        "\n",
        "Late entries will be accepted, but they cannot earn the extra 0.5 points."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e6243a88f25450b81aaad1c05dc949a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35390e83121046a1bd444a6441f8b906",
              "IPY_MODEL_996fa992ef394f80882110cefc0a23e0",
              "IPY_MODEL_fea320223da84423a8db6b5e549ce355"
            ],
            "layout": "IPY_MODEL_e859edb5f7324731906c37d5e2eed1d0"
          }
        },
        "35390e83121046a1bd444a6441f8b906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b221952b8d442d89192096f9855df3a",
            "placeholder": "​",
            "style": "IPY_MODEL_1772452d977d41c9a81188168df04869",
            "value": ""
          }
        },
        "996fa992ef394f80882110cefc0a23e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75bfba1c4c8e4d8faf11b1e9af954fc6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40fd40543136430ea7c99d44fb2a6c40",
            "value": 0
          }
        },
        "fea320223da84423a8db6b5e549ce355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e71dc20f1345ff8b6c4f13069627dd",
            "placeholder": "​",
            "style": "IPY_MODEL_90e326aa04ea4b069d5fe66d84a2b010",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e859edb5f7324731906c37d5e2eed1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b221952b8d442d89192096f9855df3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1772452d977d41c9a81188168df04869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75bfba1c4c8e4d8faf11b1e9af954fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40fd40543136430ea7c99d44fb2a6c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3e71dc20f1345ff8b6c4f13069627dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e326aa04ea4b069d5fe66d84a2b010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aabdd6d94d9481191241452c60d4f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db9144055378466785fa596c93545417",
              "IPY_MODEL_d02fe2131bff422b80fe574cd193c474",
              "IPY_MODEL_c8f0ffd6cec44c268d4860d161118f07"
            ],
            "layout": "IPY_MODEL_60ec4595dab74923912e96399a731c22"
          }
        },
        "db9144055378466785fa596c93545417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f5c46582f542dfa0ae5933373a787f",
            "placeholder": "​",
            "style": "IPY_MODEL_46116c1bd3dd49d89ac51ab491f75cc6",
            "value": "vocab.txt: 100%"
          }
        },
        "d02fe2131bff422b80fe574cd193c474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1d8c045ebb43b2a5b79eb2c9227a6d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64a38ef104e1423e8bf54e04916b69da",
            "value": 231508
          }
        },
        "c8f0ffd6cec44c268d4860d161118f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f558c1dc810e4978a9768604a4c277a7",
            "placeholder": "​",
            "style": "IPY_MODEL_59564e62791a4c7885c65d8e40e95d5a",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]"
          }
        },
        "60ec4595dab74923912e96399a731c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f5c46582f542dfa0ae5933373a787f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46116c1bd3dd49d89ac51ab491f75cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e1d8c045ebb43b2a5b79eb2c9227a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a38ef104e1423e8bf54e04916b69da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f558c1dc810e4978a9768604a4c277a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59564e62791a4c7885c65d8e40e95d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17bb4e1e1ff14b38ae6142f8ead9fbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8de8bdeca1d04233895879ddff60f6d2",
              "IPY_MODEL_98d04f76302e404c83c388596a3edba8",
              "IPY_MODEL_cc9cea8864b6412f980df8c54eb73e2c"
            ],
            "layout": "IPY_MODEL_eaf1c6c799934b648ad515679a50ac75"
          }
        },
        "8de8bdeca1d04233895879ddff60f6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50c5169b8f284e87b0df25f029695618",
            "placeholder": "​",
            "style": "IPY_MODEL_e7e7e729eb394d29899274fd3f4dda28",
            "value": "config.json: 100%"
          }
        },
        "98d04f76302e404c83c388596a3edba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52cb92f3e28546c185e0ce3f375bbfb8",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37d871d5c8954107b7b665a1d5392466",
            "value": 286
          }
        },
        "cc9cea8864b6412f980df8c54eb73e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6b29023444474d861f737ccc0ccf6d",
            "placeholder": "​",
            "style": "IPY_MODEL_689af9ee71354759a8bfecbcb16faa8f",
            "value": " 286/286 [00:00&lt;00:00, 32.1kB/s]"
          }
        },
        "eaf1c6c799934b648ad515679a50ac75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c5169b8f284e87b0df25f029695618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e7e729eb394d29899274fd3f4dda28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cb92f3e28546c185e0ce3f375bbfb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d871d5c8954107b7b665a1d5392466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df6b29023444474d861f737ccc0ccf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689af9ee71354759a8bfecbcb16faa8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c413f7e38a849feab94f3737bcae2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b07a23b664624fd4b9124f263fcdd819",
              "IPY_MODEL_1443b006e5be4293851fc653d3434a25",
              "IPY_MODEL_f1f1157d0c774a548d749d6eee4ac75b"
            ],
            "layout": "IPY_MODEL_f8608f815c2d48dd8ca6e3d8901478cf"
          }
        },
        "b07a23b664624fd4b9124f263fcdd819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552a1aaa8e0e4f4199427be97b01ad65",
            "placeholder": "​",
            "style": "IPY_MODEL_e710fe909d1c41fbb014bd2801b70a99",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1443b006e5be4293851fc653d3434a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32add54b04bf4dcf85b7c877509fb1d1",
            "max": 45106985,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72751587839f41c2aa8cbbe1c56c9ea7",
            "value": 45106985
          }
        },
        "f1f1157d0c774a548d749d6eee4ac75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed1543eaa9f445eb024da2be3758a33",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9130ccb0844d86aa4188cbfed8eb45",
            "value": " 45.1M/45.1M [00:00&lt;00:00, 176MB/s]"
          }
        },
        "f8608f815c2d48dd8ca6e3d8901478cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552a1aaa8e0e4f4199427be97b01ad65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e710fe909d1c41fbb014bd2801b70a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32add54b04bf4dcf85b7c877509fb1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72751587839f41c2aa8cbbe1c56c9ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ed1543eaa9f445eb024da2be3758a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9130ccb0844d86aa4188cbfed8eb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}